import os
import sys
import json
import asyncio
import aiohttp
import tempfile
import shutil
import subprocess
import threading
import hashlib
import time
import re
from typing import Dict, List, Any, Optional
from datetime import datetime, timedelta
import logging
from flask import Flask, request, jsonify
from flask_cors import CORS
import openai
from dataclasses import dataclass, asdict
from collections import OrderedDict
import urllib.request
import urllib.error
from rich.progress import Progress, SpinnerColumn, TimeElapsedColumn, TimeRemainingColumn, BarColumn, TextColumn
from rich.console import Console
from rich.theme import Theme

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# Create custom purple theme for progress bars
PROGRESS_THEME = Theme({
    "progress": "purple",
    "progress.bar": "purple",
    "progress.description": "purple",
    "progress.percentage": "purple",
    "progress.remaining": "purple",
    "progress.elapsed": "purple"
})

class ProgressTracker:
    """Thread-safe progress tracker using rich.progress with purple theme"""
    
    def __init__(self):
        self.progress_data = {
            'step': 'Initializing...',
            'percentage': 0,
            'elapsed_seconds': 0,
            'remaining_seconds': None,
            'total_tasks': 0,
            'completed_tasks': 0,
            'timestamp': datetime.now().isoformat()
        }
        self.lock = threading.Lock()
        self.start_time = None
        self._progress = None
        self._console = None
        
    def start_progress(self, total_tasks: int, initial_step: str = "Starting scan..."):
        """Initialize progress tracking"""
        with self.lock:
            self.start_time = datetime.now()
            self.progress_data.update({
                'step': initial_step,
                'percentage': 0,
                'elapsed_seconds': 0,
                'remaining_seconds': None,
                'total_tasks': total_tasks,
                'completed_tasks': 0,
                'timestamp': datetime.now().isoformat()
            })
            
            # Update global scan state for cross-thread access
            global current_scan_state, current_scan_lock
            try:
                with current_scan_lock:
                    current_scan_state.update({
                        'is_running': True,
                        'step': initial_step,
                        'percentage': 0,
                        'total_tasks': total_tasks,
                        'completed_tasks': 0,
                        'start_time': self.start_time,
                        'elapsed_seconds': 0,
                        'remaining_seconds': None
                    })
                logger.info(f"ðŸ”’ GLOBAL STATE STARTED: {initial_step} - is_running: True - total_tasks: {total_tasks}")
            except Exception as e:
                logger.error(f"âŒ GLOBAL STATE START FAILED: {e}")
                # This is critical - if we can't start global state, progress won't work
            
            # Create rich progress bar
            self._progress = Progress(
                SpinnerColumn(),
                TextColumn("[purple]{task.description}"),
                BarColumn(bar_width=40, complete_style="purple", finished_style="purple"),
                TextColumn("[purple]{task.percentage:>3.0f}%"),
                TimeElapsedColumn(),
                TimeRemainingColumn(),
                console=Console(theme=PROGRESS_THEME),
                expand=True
            )
            
            self._progress.start()
            self._progress.add_task(initial_step, total=total_tasks)
            logger.info(f"ðŸš€ Progress tracking started: {total_tasks} total tasks")
    
    def update_progress(self, step: str, completed_tasks: int = None, advance: int = 1):
        """Update progress with new step and completion count"""
        with self.lock:
            if self._progress is None:
                logger.warning("âš ï¸ Progress not started, cannot update")
                return
                
            if completed_tasks is not None:
                self.progress_data['completed_tasks'] = completed_tasks
            else:
                self.progress_data['completed_tasks'] += advance
                
            # Calculate percentage
            if self.progress_data['total_tasks'] > 0:
                percentage = min(100, (self.progress_data['completed_tasks'] / self.progress_data['total_tasks']) * 100)
            else:
                percentage = 0
                
            # Calculate time metrics
            if self.start_time:
                elapsed = (datetime.now() - self.start_time).total_seconds()
                self.progress_data['elapsed_seconds'] = elapsed
                
                if percentage > 0:
                    # Estimate remaining time based on current rate
                    estimated_total = elapsed / (percentage / 100)
                    remaining = max(0, estimated_total - elapsed)
                    self.progress_data['remaining_seconds'] = remaining
                else:
                    self.progress_data['remaining_seconds'] = None
            
            # Update rich progress bar
            if self._progress.tasks:
                task = self._progress.tasks[0]
                self._progress.update(
                    task.id,
                    description=step,
                    completed=self.progress_data['completed_tasks'],
                    total=self.progress_data['total_tasks']
                )
            
            # Update progress data
            self.progress_data.update({
                'step': step,
                'percentage': round(percentage, 1),
                'timestamp': datetime.now().isoformat()
            })
            
            # Update global scan state for cross-thread access
            global current_scan_state, current_scan_lock
            try:
                percent_value = round(percentage, 1)
                with current_scan_lock:
                    current_scan_state.update({
                        'is_running': True,  # Keep scan marked as running
                        'step': step,
                        'percentage': percent_value,
                        'completed_tasks': self.progress_data['completed_tasks'],
                        'elapsed_seconds': self.progress_data['elapsed_seconds'],
                        'remaining_seconds': self.progress_data['remaining_seconds']
                    })
                logger.info(f"ðŸ”’ GLOBAL STATE UPDATED: {step} - {percent_value}% - is_running: True")
                # Also push to webhook (throttled)
                maybe_send_progress_webhook(step, percent_value)
            except Exception as e:
                logger.error(f"âŒ GLOBAL STATE UPDATE FAILED: {e}")
                # This is critical - if we can't update global state, progress won't work
            
            logger.info(f"ðŸ“Š Progress: {step} - {percentage:.1f}% ({self.progress_data['completed_tasks']}/{self.progress_data['total_tasks']})")
    
    def get_progress_data(self) -> Dict[str, Any]:
        """Get current progress data (thread-safe)"""
        with self.lock:
            return self.progress_data.copy()
    
    def complete_progress(self, final_step: str = "Scan completed"):
        """Mark progress as complete"""
        with self.lock:
            if self._progress:
                self._progress.update(0, description=final_step, completed=self.progress_data['total_tasks'])
                self._progress.stop()
                self._progress = None
            
            self.progress_data.update({
                'step': final_step,
                'percentage': 100,
                'completed_tasks': self.progress_data['total_tasks'],
                'remaining_seconds': 0,
                'timestamp': datetime.now().isoformat()
            })
            
            # Update global scan state for cross-thread access
            global current_scan_state, current_scan_lock
            with current_scan_lock:
                current_scan_state.update({
                    'is_running': False,  # Mark as completed
                    'step': final_step,
                    'percentage': 100,
                    'completed_tasks': self.progress_data['total_tasks'],
                    'elapsed_seconds': self.progress_data.get('elapsed_seconds', 0),
                    'remaining_seconds': 0
                })
            
            logger.info(f"âœ… Progress completed: {final_step}")
    
    def cleanup(self):
        """Clean up progress resources"""
        with self.lock:
            if self._progress:
                self._progress.stop()
                self._progress = None
            
            # Update global scan state for cross-thread access
            global current_scan_state, current_scan_lock
            with current_scan_lock:
                current_scan_state.update({
                    'is_running': False,
                    'step': 'No scan running',
                    'percentage': 0,
                    'total_tasks': 0,
                    'completed_tasks': 0,
                    'start_time': None,
                    'elapsed_seconds': 0,
                    'remaining_seconds': None
                })

# Global progress tracker instance
progress_tracker = ProgressTracker()

# Global scan state for cross-thread access
current_scan_state = {
    'is_running': False,
    'step': 'No scan running',
    'percentage': 0,
    'total_tasks': 0,
    'completed_tasks': 0,
    'start_time': None,
    'elapsed_seconds': 0,
    'remaining_seconds': None
}
current_scan_lock = threading.Lock()

# Global progress push configuration (for Firestore via backend webhook)
GLOBAL_AUDIT_ID: Optional[str] = None
GLOBAL_PROGRESS_WEBHOOK_URL: Optional[str] = None
GLOBAL_LAST_PROGRESS_WEBHOOK_SENT_TS: float = 0.0
GLOBAL_LAST_PROGRESS_STEP: Optional[str] = None
GLOBAL_LAST_PROGRESS_PERCENT: Optional[float] = None

# Throttled progress webhook sender (every ~3s or on milestone change)
def maybe_send_progress_webhook(step: str, percent: float) -> None:
    try:
        global GLOBAL_AUDIT_ID, GLOBAL_PROGRESS_WEBHOOK_URL
        global GLOBAL_LAST_PROGRESS_WEBHOOK_SENT_TS, GLOBAL_LAST_PROGRESS_STEP, GLOBAL_LAST_PROGRESS_PERCENT
        if not GLOBAL_AUDIT_ID or not GLOBAL_PROGRESS_WEBHOOK_URL:
            return

        now = time.time()
        is_milestone_change = (GLOBAL_LAST_PROGRESS_STEP != step) or (GLOBAL_LAST_PROGRESS_PERCENT != percent)
        should_send = is_milestone_change or (now - GLOBAL_LAST_PROGRESS_WEBHOOK_SENT_TS >= 2.5) or percent >= 100.0
        if not should_send:
            return

        payload = {
            'audit_id': GLOBAL_AUDIT_ID,
            'status': 'running' if percent < 100.0 else 'completed',
            'progress': {
                'step': step,
                'progress': round(percent, 1),
                'timestamp': datetime.now().isoformat()
            }
        }
        try:
            import requests
            requests.post(GLOBAL_PROGRESS_WEBHOOK_URL, json=payload, timeout=5)
            GLOBAL_LAST_PROGRESS_WEBHOOK_SENT_TS = now
            GLOBAL_LAST_PROGRESS_STEP = step
            GLOBAL_LAST_PROGRESS_PERCENT = percent
            logger.info(f"ðŸ“¡ PROGRESS WEBHOOK SENT: {round(percent,1)}% - {step}")
        except Exception as webhook_err:
            logger.warning(f"âš ï¸ Progress webhook failed: {webhook_err}")
    except Exception as e:
        logger.error(f"âŒ maybe_send_progress_webhook error: {e}")

# DEBUG: Log initial global state
logger.info(f"ðŸ” INITIAL GLOBAL STATE: {current_scan_state}")

class DependencyAnalyzer:
    """Analyzes dependencies to eliminate false positives about unused packages"""
    
    def __init__(self):
        self.supported_package_managers = {
            'node': ['package.json', 'package-lock.json', 'yarn.lock'],
            'python': ['requirements.txt', 'pyproject.toml', 'Pipfile', 'poetry.lock'],
            'go': ['go.mod', 'go.sum'],
            'rust': ['Cargo.toml', 'Cargo.lock'],
            'php': ['composer.json', 'composer.lock'],
            'java': ['pom.xml', 'build.gradle', 'gradle.lockfile'],
            'ruby': ['Gemfile', 'Gemfile.lock'],
            'dotnet': ['*.csproj', '*.vbproj', 'packages.config']
        }
    
    def analyze_dependencies(self, repo_path: str) -> Dict[str, Any]:
        """Analyze all dependencies in the repository"""
        analysis = {
            'package_manager': None,
            'dependencies': {},
            'dev_dependencies': {},
            'lock_files': [],
            'imports_found': {},
            'unused_packages': [],
            'framework_detected': None
        }
        
        try:
            # Detect package manager
            for lang, files in self.supported_package_managers.items():
                for file in files:
                    if os.path.exists(os.path.join(repo_path, file)):
                        analysis['package_manager'] = lang
                        break
                if analysis['package_manager']:
                    break
            
            # Analyze based on detected package manager
            if analysis['package_manager'] == 'node':
                analysis.update(self._analyze_node_dependencies(repo_path))
            elif analysis['package_manager'] == 'python':
                analysis.update(self._analyze_python_dependencies(repo_path))
            elif analysis['package_manager'] == 'go':
                analysis.update(self._analyze_go_dependencies(repo_path))
            elif analysis['package_manager'] == 'rust':
                analysis.update(self._analyze_rust_dependencies(repo_path))
            
            # Scan for actual imports/usage
            analysis['imports_found'] = self._scan_for_imports(repo_path, analysis['package_manager'])
            
            # Identify truly unused packages
            analysis['unused_packages'] = self._identify_unused_packages(analysis)
            
        except Exception as e:
            logger.warning(f"âš ï¸ Dependency analysis failed: {e}")
        
        return analysis
    
    def _analyze_node_dependencies(self, repo_path: str) -> Dict[str, Any]:
        """Analyze Node.js dependencies"""
        try:
            package_json_path = os.path.join(repo_path, 'package.json')
            if not os.path.exists(package_json_path):
                return {}
            
            with open(package_json_path, 'r', encoding='utf-8') as f:
                package_data = json.load(f)
            
            return {
                'dependencies': package_data.get('dependencies', {}),
                'dev_dependencies': package_data.get('devDependencies', {}),
                'framework_detected': self._detect_node_framework(package_data)
            }
        except Exception as e:
            logger.warning(f"âš ï¸ Node.js dependency analysis failed: {e}")
            return {}
    
    def _detect_node_framework(self, package_data: Dict) -> str:
        """Detect Node.js framework"""
        dependencies = {**package_data.get('dependencies', {}), **package_data.get('devDependencies', {})}
        
        if 'next' in dependencies:
            return 'Next.js'
        elif 'react' in dependencies and 'react-dom' in dependencies:
            return 'React'
        elif 'express' in dependencies:
            return 'Express.js'
        elif 'vue' in dependencies:
            return 'Vue.js'
        elif 'angular' in dependencies:
            return 'Angular'
        elif 'nuxt' in dependencies:
            return 'Nuxt.js'
        else:
            return 'Node.js'
    
    def _scan_for_imports(self, repo_path: str, package_manager: str) -> Dict[str, List[str]]:
        """Scan for actual imports/usage of packages"""
        imports = {}
        
        try:
            if package_manager == 'node':
                imports = self._scan_node_imports(repo_path)
            elif package_manager == 'python':
                imports = self._scan_python_imports(repo_path)
            elif package_manager == 'go':
                imports = self._scan_go_imports(repo_path)
            elif package_manager == 'rust':
                imports = self._scan_rust_imports(repo_path)
        except Exception as e:
            logger.warning(f"âš ï¸ Import scanning failed: {e}")
        
        return imports
    
    def _scan_node_imports(self, repo_path: str) -> Dict[str, List[str]]:
        """Scan for Node.js imports"""
        imports = {}
        
        # Common file extensions for Node.js
        extensions = ['.js', '.jsx', '.ts', '.tsx', '.mjs']
        
        for root, dirs, files in os.walk(repo_path):
            # Skip node_modules and other build directories
            if 'node_modules' in root or 'dist' in root or 'build' in root:
                continue
            
            for file in files:
                if any(file.endswith(ext) for ext in extensions):
                    file_path = os.path.join(root, file)
                    try:
                        with open(file_path, 'r', encoding='utf-8') as f:
                            content = f.read()
                            
                        # Look for various import patterns
                        import_patterns = [
                            r'import\s+.*\s+from\s+[\'"]([^\'"]+)[\'"]',
                            r'require\s*\(\s*[\'"]([^\'"]+)[\'"]',
                            r'import\s+[\'"]([^\'"]+)[\'"]',
                            r'from\s+[\'"]([^\'"]+)[\'"]'
                        ]
                        
                        for pattern in import_patterns:
                            matches = re.findall(pattern, content)
                            for match in matches:
                                # Extract package name (before first slash)
                                package_name = match.split('/')[0]
                                if package_name not in imports:
                                    imports[package_name] = []
                                imports[package_name].append(file_path)
                    except Exception as e:
                        continue
        
        return imports
    
    def _identify_unused_packages(self, analysis: Dict[str, Any]) -> List[str]:
        """Identify truly unused packages"""
        unused = []
        
        if not analysis.get('dependencies'):
            return unused
        
        dependencies = analysis['dependencies']
        imports = analysis['imports_found']
        
        for package in dependencies:
            if package not in imports:
                # Check if it's a framework or commonly used package
                if not self._is_commonly_used_package(package):
                    unused.append(package)
        
        return unused
    
    def _is_commonly_used_package(self, package: str) -> bool:
        """Check if package is commonly used and shouldn't be flagged"""
        common_packages = {
            'react', 'react-dom', 'next', 'typescript', '@types/node',
            'tailwindcss', 'postcss', 'autoprefixer', 'eslint', 'prettier',
            'jest', 'cypress', 'playwright', 'storybook'
        }
        return package in common_packages

class FrameworkDetector:
    """Detects frameworks and technologies to provide context-aware security analysis"""
    
    def __init__(self):
        self.frameworks = {
            'nextjs': {
                'indicators': ['next.config.js', 'next.config.ts', 'pages/', 'app/'],
                'security_patterns': ['middleware.ts', 'next-auth', 'csrf'],
                'common_vulnerabilities': ['CSP', 'XSS', 'CSRF', 'authentication']
            },
            'react': {
                'indicators': ['package.json:react', 'src/', 'components/'],
                'security_patterns': ['useEffect', 'useState', 'Context'],
                'common_vulnerabilities': ['XSS', 'injection', 'state_management']
            },
            'express': {
                'indicators': ['package.json:express', 'server.js', 'app.js'],
                'security_patterns': ['helmet', 'cors', 'rate-limiting'],
                'common_vulnerabilities': ['injection', 'authentication', 'authorization']
            },
            'django': {
                'indicators': ['manage.py', 'settings.py', 'urls.py'],
                'security_patterns': ['csrf_token', 'authentication', 'permissions'],
                'common_vulnerabilities': ['CSRF', 'XSS', 'SQL_injection']
            },
            'flask': {
                'indicators': ['app.py', 'requirements.txt:flask'],
                'security_patterns': ['flask-login', 'flask-security'],
                'common_vulnerabilities': ['CSRF', 'XSS', 'authentication']
            }
        }
    
    def detect_framework(self, repo_path: str) -> Dict[str, Any]:
        """Detect framework and provide security context"""
        detected = {
            'primary_framework': None,
            'secondary_frameworks': [],
            'security_patterns': [],
            'missing_security': [],
            'recommendations': []
        }
        
        try:
            for framework, info in self.frameworks.items():
                if self._check_framework_indicators(repo_path, info['indicators']):
                    if not detected['primary_framework']:
                        detected['primary_framework'] = framework
                    else:
                        detected['secondary_frameworks'].append(framework)
                    
                    # Check for security patterns
                    detected['security_patterns'].extend(info['security_patterns'])
                    
                    # Check for missing security measures
                    missing = self._check_missing_security(repo_path, info['common_vulnerabilities'])
                    detected['missing_security'].extend(missing)
            
            # Generate framework-specific recommendations
            detected['recommendations'] = self._generate_framework_recommendations(detected)
            
        except Exception as e:
            logger.warning(f"âš ï¸ Framework detection failed: {e}")
        
        return detected
    
    def _check_framework_indicators(self, repo_path: str, indicators: List[str]) -> bool:
        """Check if framework indicators exist"""
        for indicator in indicators:
            if ':' in indicator:  # package.json:package_name format
                package_name = indicator.split(':')[1]
                if self._check_package_dependency(repo_path, package_name):
                    return True
            elif os.path.exists(os.path.join(repo_path, indicator)):
                return True
        return False
    
    def _check_package_dependency(self, repo_path: str, package_name: str) -> bool:
        """Check if package is in dependencies"""
        try:
            package_json_path = os.path.join(repo_path, 'package.json')
            if os.path.exists(package_json_path):
                with open(package_json_path, 'r', encoding='utf-8') as f:
                    package_data = json.load(f)
                
                dependencies = {**package_data.get('dependencies', {}), **package_data.get('devDependencies', {})}
                return package_name in dependencies
        except Exception:
            pass
        return False
    
    def _check_missing_security(self, repo_path: str, vulnerabilities: List[str]) -> List[str]:
        """Check for missing security measures"""
        missing = []
        
        for vuln in vulnerabilities:
            if not self._has_security_measure(repo_path, vuln):
                missing.append(vuln)
        
        return missing
    
    def _has_security_measure(self, repo_path: str, vulnerability: str) -> bool:
        """Check if security measure exists"""
        security_files = {
            'csrf': ['middleware.ts', 'csrf.ts', 'csrf-token'],
            'xss': ['xss.ts', 'sanitize.ts', 'escape.ts'],
            'authentication': ['auth.ts', 'login.ts', 'middleware.ts'],
            'rate_limiting': ['rate-limit.ts', 'throttle.ts', 'limiter.ts']
        }
        
        if vulnerability.lower() in security_files:
            for file_pattern in security_files[vulnerability.lower()]:
                if self._file_exists_pattern(repo_path, file_pattern):
                    return True
        
        return False
    
    def _file_exists_pattern(self, repo_path: str, pattern: str) -> bool:
        """Check if file exists with pattern"""
        for root, dirs, files in os.walk(repo_path):
            for file in files:
                if pattern in file:
                    return True
        return False
    
    def _generate_framework_recommendations(self, detected: Dict[str, Any]) -> List[str]:
        """Generate framework-specific security recommendations"""
        recommendations = []
        framework = detected.get('primary_framework')
        
        if framework == 'nextjs':
            recommendations.extend([
                'Implement middleware.ts for authentication and CSRF protection',
                'Use next-auth for secure authentication',
                'Configure Content Security Policy in next.config.js',
                'Implement rate limiting for API routes'
            ])
        elif framework == 'react':
            recommendations.extend([
                'Use React.memo and useMemo for performance',
                'Implement proper error boundaries',
                'Sanitize user input before rendering',
                'Use HTTPS-only cookies and secure storage'
            ])
        elif framework == 'express':
            recommendations.extend([
                'Use helmet.js for security headers',
                'Implement CORS with specific origins',
                'Add rate limiting with express-rate-limit',
                'Validate and sanitize all inputs'
            ])
        
        return recommendations
    
    def _analyze_python_dependencies(self, repo_path: str) -> Dict[str, Any]:
        """Analyze Python dependencies"""
        try:
            requirements_path = os.path.join(repo_path, 'requirements.txt')
            if os.path.exists(requirements_path):
                with open(requirements_path, 'r', encoding='utf-8') as f:
                    requirements = f.read().splitlines()
                
                dependencies = [req.split('==')[0].split('>=')[0].split('<=')[0].strip() for req in requirements if req.strip() and not req.startswith('#')]
                
                return {
                    'dependencies': {dep: 'latest' for dep in dependencies},
                    'framework_detected': self._detect_python_framework(dependencies)
                }
        except Exception as e:
            logger.warning(f"âš ï¸ Python dependency analysis failed: {e}")
        return {}
    
    def _detect_python_framework(self, dependencies: List[str]) -> str:
        """Detect Python framework"""
        if 'django' in dependencies:
            return 'Django'
        elif 'flask' in dependencies:
            return 'Flask'
        elif 'fastapi' in dependencies:
            return 'FastAPI'
        elif 'tornado' in dependencies:
            return 'Tornado'
        else:
            return 'Python'
    
    def _analyze_go_dependencies(self, repo_path: str) -> Dict[str, Any]:
        """Analyze Go dependencies"""
        try:
            go_mod_path = os.path.join(repo_path, 'go.mod')
            if os.path.exists(go_mod_path):
                with open(go_mod_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                # Simple parsing of go.mod
                dependencies = []
                for line in content.split('\n'):
                    if line.startswith('require ') and not line.startswith('require ('):
                        dep = line.split(' ')[1]
                        dependencies.append(dep)
                
                return {
                    'dependencies': {dep: 'latest' for dep in dependencies},
                    'framework_detected': 'Go'
                }
        except Exception as e:
            logger.warning(f"âš ï¸ Go dependency analysis failed: {e}")
        return {}
    
    def _analyze_rust_dependencies(self, repo_path: str) -> Dict[str, Any]:
        """Analyze Rust dependencies"""
        try:
            cargo_toml_path = os.path.join(repo_path, 'Cargo.toml')
            if os.path.exists(cargo_toml_path):
                with open(cargo_toml_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                
                # Simple parsing of Cargo.toml
                dependencies = []
                lines = content.split('\n')
                in_dependencies = False
                
                for line in lines:
                    if '[dependencies]' in line:
                        in_dependencies = True
                        continue
                    elif line.startswith('[') and ']' in line:
                        in_dependencies = False
                        continue
                    
                    if in_dependencies and '=' in line and not line.startswith('#'):
                        dep = line.split('=')[0].strip()
                        dependencies.append(dep)
                
                return {
                    'dependencies': {dep: 'latest' for dep in dependencies},
                    'framework_detected': 'Rust'
                }
        except Exception as e:
            logger.warning(f"âš ï¸ Rust dependency analysis failed: {e}")
        return {}
    
    def _scan_python_imports(self, repo_path: str) -> Dict[str, List[str]]:
        """Scan for Python imports"""
        imports = {}
        extensions = ['.py', '.pyx', '.pyi']
        
        for root, dirs, files in os.walk(repo_path):
            if '__pycache__' in root or '.venv' in root or 'venv' in root:
                continue
            
            for file in files:
                if any(file.endswith(ext) for ext in extensions):
                    file_path = os.path.join(root, file)
                    try:
                        with open(file_path, 'r', encoding='utf-8') as f:
                            content = f.read()
                        
                        # Look for Python import patterns
                        import_patterns = [
                            r'import\s+([a-zA-Z_][a-zA-Z0-9_]*)',
                            r'from\s+([a-zA-Z_][a-zA-Z0-9_]*)\s+import',
                            r'import\s+([a-zA-Z_][a-zA-Z0-9_]*)\s+as'
                        ]
                        
                        for pattern in import_patterns:
                            matches = re.findall(pattern, content)
                            for match in matches:
                                if match not in imports:
                                    imports[match] = []
                                imports[match].append(file_path)
                    except Exception:
                        continue
        
        return imports
    
    def _scan_go_imports(self, repo_path: str) -> Dict[str, List[str]]:
        """Scan for Go imports"""
        imports = {}
        extensions = ['.go']
        
        for root, dirs, files in os.walk(repo_path):
            if 'vendor' in root or 'node_modules' in root:
                continue
            
            for file in files:
                if any(file.endswith(ext) for ext in extensions):
                    file_path = os.path.join(root, file)
                    try:
                        with open(file_path, 'r', encoding='utf-8') as f:
                            content = f.read()
                        
                        # Look for Go import patterns
                        import_patterns = [
                            r'import\s+[\'"]([^\'"]+)[\'"]',
                            r'import\s+\(\s*[\'"]([^\'"]+)[\'"]'
                        ]
                        
                        for pattern in import_patterns:
                            matches = re.findall(pattern, content)
                            for match in matches:
                                package_name = match.split('/')[0]
                                if package_name not in imports:
                                    imports[package_name] = []
                                imports[package_name].append(file_path)
                    except Exception:
                        continue
        
        return imports
    
    def _scan_rust_imports(self, repo_path: str) -> Dict[str, List[str]]:
        """Scan for Rust imports"""
        imports = {}
        extensions = ['.rs']
        
        for root, dirs, files in os.walk(repo_path):
            if 'target' in root or 'node_modules' in root:
                continue
            
            for file in files:
                if any(file.endswith(ext) for ext in extensions):
                    file_path = os.path.join(root, file)
                    try:
                        with open(file_path, 'r', encoding='utf-8') as f:
                            content = f.read()
                        
                        # Look for Rust import patterns
                        import_patterns = [
                            r'use\s+([a-zA-Z_][a-zA-Z0-9_:]*)',
                            r'extern\s+crate\s+([a-zA-Z_][a-zA-Z0-9_]*)'
                        ]
                        
                        for pattern in import_patterns:
                            matches = re.findall(pattern, content)
                            for match in matches:
                                package_name = match.split('::')[0]
                                if package_name not in imports:
                                    imports[package_name] = []
                                imports[package_name].append(file_path)
                    except Exception:
                        continue
        
        return imports
    
    def get_language_security_context(self, file_type: str, file_path: str) -> str:
        """Get language-specific security context for analysis"""
        language_contexts = {
            # JavaScript/TypeScript Ecosystem
            '.js': """
            **JAVASCRIPT/TYPESCRIPT SECURITY CONTEXT**:
            - Watch for eval(), Function(), setTimeout with user input
            - Check for innerHTML, outerHTML, document.write with user data
            - Look for prototype pollution in object operations
            - Verify proper input sanitization before DOM manipulation
            - Check for insecure JSON.parse with user input
            - Look for missing CSRF tokens in form submissions
            - Verify proper authentication checks in API calls
            """,
            '.ts': """
            **TYPESCRIPT SECURITY CONTEXT**:
            - Same as JavaScript plus type safety considerations
            - Check for type bypasses that could lead to security issues
            - Verify proper interface validation for user inputs
            - Look for any type assertions that could be dangerous
            """,
            '.tsx': """
            **REACT TYPESCRIPT SECURITY CONTEXT**:
            - Check for dangerouslySetInnerHTML usage
            - Verify proper prop validation and sanitization
            - Look for missing authentication in protected routes
            - Check for proper state management security
            - Verify proper error boundary implementation
            """,
            '.jsx': """
            **REACT JAVASCRIPT SECURITY CONTEXT**:
            - Check for dangerouslySetInnerHTML usage
            - Verify proper prop validation and sanitization
            - Look for missing authentication in protected routes
            - Check for proper state management security
            """,
            # Python Ecosystem
            '.py': """
            **PYTHON SECURITY CONTEXT**:
            - Check for eval(), exec(), input() with user data
            - Look for SQL injection in raw SQL queries
            - Verify proper input validation and sanitization
            - Check for path traversal in file operations
            - Look for insecure deserialization (pickle, yaml)
            - Verify proper authentication and authorization
            - Check for CSRF protection in web frameworks
            """,
            # Go Ecosystem
            '.go': """
            **GO SECURITY CONTEXT**:
            - Check for SQL injection in raw queries
            - Verify proper input validation and sanitization
            - Look for path traversal in file operations
            - Check for proper authentication middleware
            - Verify proper CORS configuration
            - Look for insecure deserialization
            """,
            # Rust Ecosystem
            '.rs': """
            **RUST SECURITY CONTEXT**:
            - Check for unsafe blocks with user input
            - Verify proper input validation and sanitization
            - Look for path traversal in file operations
            - Check for proper authentication handling
            - Verify proper error handling without information disclosure
            """,
            # PHP Ecosystem
            '.php': """
            **PHP SECURITY CONTEXT**:
            - Check for SQL injection in raw queries
            - Look for XSS in echo/print statements
            - Verify proper input validation and sanitization
            - Check for file inclusion vulnerabilities
            - Look for command injection in shell_exec, system
            - Verify proper session security
            """,
            # Java Ecosystem
            '.java': """
            **JAVA SECURITY CONTEXT**:
            - Check for SQL injection in raw queries
            - Look for XSS in JSP output
            - Verify proper input validation and sanitization
            - Check for insecure deserialization
            - Look for path traversal in file operations
            - Verify proper authentication and authorization
            """,
            # C# Ecosystem
            '.cs': """
            **C# SECURITY CONTEXT**:
            - Check for SQL injection in raw queries
            - Look for XSS in Razor views
            - Verify proper input validation and sanitization
            - Check for insecure deserialization
            - Look for path traversal in file operations
            - Verify proper authentication and authorization
            """,
            # Web Technologies
            '.html': """
            **HTML SECURITY CONTEXT**:
            - Check for XSS in user-generated content
            - Look for clickjacking vulnerabilities
            - Verify proper CSP headers
            - Check for form injection attacks
            - Look for insecure iframe usage
            """,
            '.vue': """
            **VUE.JS SECURITY CONTEXT**:
            - Check for v-html with user input
            - Verify proper prop validation
            - Look for missing authentication in routes
            - Check for proper state management security
            - Verify proper error handling
            """,
            # Configuration Files
            '.yaml': """
            **YAML SECURITY CONTEXT**:
            - Check for YAML deserialization vulnerabilities
            - Look for exposed secrets in configuration
            - Verify proper access controls
            - Check for insecure default values
            """,
            '.json': """
            **JSON SECURITY CONTEXT**:
            - Check for exposed secrets in configuration
            - Look for insecure default values
            - Verify proper access controls
            - Check for dependency vulnerabilities
            """,
            # Shell Scripts
            '.sh': """
            **SHELL SCRIPT SECURITY CONTEXT**:
            - Check for command injection in user input
            - Look for path traversal vulnerabilities
            - Verify proper input validation
            - Check for insecure file permissions
            - Look for exposed secrets in scripts
            """,
            # Docker & Infrastructure
            '.dockerfile': """
            **DOCKER SECURITY CONTEXT**:
            - Check for running as root user
            - Look for exposed ports and services
            - Verify proper user permissions
            - Check for insecure base images
            - Look for exposed secrets in layers
            """,
            # Database
            '.sql': """
            **SQL SECURITY CONTEXT**:
            - Check for SQL injection vulnerabilities
            - Look for exposed database credentials
            - Verify proper access controls
            - Check for insecure default configurations
            - Look for missing input validation
            """
        }
        
        # Get the most specific context for the file type
        for ext, context in language_contexts.items():
            if file_path.endswith(ext):
                return context
        
        # Default context for unknown file types
        return """
        **GENERAL SECURITY CONTEXT**:
        - Check for common web application vulnerabilities
        - Verify proper input validation and sanitization
        - Look for authentication and authorization issues
        - Check for information disclosure vulnerabilities
        - Verify proper error handling
        """



# Configuration
MAX_REPO_SIZE_MB = 500
MAX_SCAN_TIME_SECONDS = 300  # 5 minutes
ALLOWED_REPO_DOMAINS = ['github.com', 'gitlab.com', 'bitbucket.org']

@dataclass
class SecurityFinding:
    """Represents a security finding with all details"""
    rule_id: str
    severity: str  # Critical, High, Medium, Low
    message: str
    description: str
    file_path: str
    line_number: int
    end_line: int
    code_snippet: str
    cwe_ids: List[str]
    owasp_ids: List[str]
    impact: str
    likelihood: str
    confidence: str
    occurrences: int = 1

@dataclass
class SecurityReport:
    """Complete security audit report"""
    summary: Dict[str, Any]
    findings: List[SecurityFinding]
    condensed_findings: List[SecurityFinding]
    condensed_remediations: Dict[str, str]  # rule_id -> remediation prompt
    scan_duration: float
    timestamp: str
    repository_info: Dict[str, Any]

class FalsePositiveFilter:
    """Filters out false positives based on context and patterns"""
    
    def __init__(self):
        self.false_positive_patterns = {
            'unused_package': [
                'package is not used anywhere in the code',
                'unused dependency',
                'unused import'
            ],
            'framework_specific': [
                'missing csrf protection',  # Might be handled by framework
                'missing xss protection',   # Might be handled by framework
                'insecure default'          # Might be framework default
            ],
            'development_only': [
                'console.log',
                'debug mode',
                'development server'
            ]
        }
    
    def filter_findings(self, findings: List[SecurityFinding], context: Dict[str, Any]) -> List[SecurityFinding]:
        """Filter out false positives based on context"""
        filtered_findings = []
        
        for finding in findings:
            if self._below_confidence_threshold(finding):
                continue
            if not self._is_false_positive(finding, context):
                filtered_findings.append(finding)
            else:
                logger.info(f"ðŸ” Filtered out false positive: {finding.message}")
        
        return filtered_findings
    
    def _is_false_positive(self, finding: SecurityFinding, context: Dict[str, Any]) -> bool:
        """Check if finding is a false positive"""
        # Check for unused package false positives
        if 'unused' in finding.message.lower() and 'package' in finding.message.lower():
            if context.get('dependencies', {}).get('unused_packages', []):
                # Check if this specific package is actually unused
                package_name = self._extract_package_name(finding.message)
                if package_name in context['dependencies']['unused_packages']:
                    return True
        
        # Check for framework-specific false positives
        framework = context.get('framework', {}).get('primary_framework')
        if framework:
            if self._is_framework_handled_issue(finding, framework):
                return True
        
        return False
    
    def _extract_package_name(self, message: str) -> str:
        """Extract package name from finding message"""
        # Simple extraction - could be improved with regex
        words = message.split()
        for i, word in enumerate(words):
            if word.lower() in ['package', 'dependency', 'library'] and i + 1 < len(words):
                return words[i + 1].strip("'\".,")
        return ""
    
    def _is_framework_handled_issue(self, finding: SecurityFinding, framework: str) -> bool:
        """Check if finding is handled by framework"""
        framework_handlers = {
            'nextjs': ['csrf', 'xss', 'authentication', 'csp'],
            'react': ['xss', 'state_management'],
            'express': ['cors', 'helmet', 'rate_limiting'],
            'django': ['csrf', 'xss', 'authentication'],
            'flask': ['csrf', 'authentication']
        }
        
        if framework in framework_handlers:
            for handler in framework_handlers[framework]:
                if handler in finding.message.lower():
                    return True
        
        return False
    
    def _below_confidence_threshold(self, finding: SecurityFinding) -> bool:
        """Drop Low-confidence findings by default"""
        confidence = (finding.confidence or '').strip().lower()
        return confidence in ('', 'low')

class EvidenceFilter:
    """Validates findings against actual file content to reduce false positives"""

    def filter_by_evidence(self, findings: List[SecurityFinding], file_content: str) -> List[SecurityFinding]:
        filtered: List[SecurityFinding] = []
        try:
            lines = file_content.splitlines()
            total_lines = len(lines)
        except Exception:
            lines = []
            total_lines = 0

        for finding in findings:
            try:
                # Require basic fields
                if not finding.code_snippet or finding.line_number is None:
                    continue

                # Validate line bounds (allow 1-based or 0-based inputs)
                start_line = max(1, int(finding.line_number or 1))
                end_line = int(finding.end_line or start_line)
                if total_lines and (start_line > total_lines or end_line > total_lines):
                    continue

                # Require snippet to exist verbatim in file and be meaningful length
                snippet = finding.code_snippet.strip()
                if len(snippet) < 8:
                    continue
                if not snippet or snippet not in file_content:
                    continue

                # Apply stricter gate for low-confidence findings
                confidence = (finding.confidence or '').lower()
                if confidence in ('', 'low') and not self._looks_risky(finding):
                    continue

                filtered.append(finding)
            except Exception:
                # On any validation error, skip the finding
                continue

        return filtered

    def _looks_risky(self, finding: SecurityFinding) -> bool:
        message = (finding.message or '').lower()
        rule_id = (finding.rule_id or '').lower()
        snippet = (finding.code_snippet or '').lower()
        path = (finding.file_path or '').replace('\\', '/').lower()

        # Heuristics for common classes of vulns
        if 'xss' in message or 'xss' in rule_id:
            # Only consider real sinks
            risky_sinks = (
                'dangerouslysetinnerhtml' in snippet or
                'innerhtml' in snippet or
                'insertadjacenthtml' in snippet
            )
            return risky_sinks
        if 'sql' in message or 'sql' in rule_id:
            risky_ops = any(tok in snippet for tok in ('select', 'insert', 'update', 'delete'))
            string_building = any(tok in snippet for tok in ('+', '%', 'format(', '{'))
            return risky_ops and string_building
        if 'csrf' in message or 'csrf' in rule_id:
            # Only count if this is likely a server-side route or explicit POST client code
            server_route = '/src/app/api/' in path or '/api/' in path
            client_post = ('fetch(' in snippet and ("method: 'post'" in snippet or 'method:"post"' in snippet or 'method: "POST"' in snippet or "method: 'POST'" in snippet)) or '.post(' in snippet
            return server_route or client_post
        if 'path traversal' in message or 'traversal' in rule_id:
            return '..' in snippet or '/..' in snippet
        return False

class ChatGPTSecurityScanner:
    """Ultimate ChatGPT-powered security scanner for indie developers"""
    
    def __init__(self):
        # Initialize OpenAI clients with multiple API keys for parallel processing
        self.api_keys = []
        
        # Try to get multiple API keys for parallel processing
        primary_key = os.environ.get('OPENAI_API_KEY')
        if primary_key:
            self.api_keys.append(primary_key)
        
        # Try to get additional API keys (support up to 8 keys for 4 workers Ã— 2 keys each)
        for i in range(1, 9):  # Support up to 8 API keys
            additional_key = os.environ.get(f'OPENAI_API_KEY_{i}')
            if additional_key:
                self.api_keys.append(additional_key)
        
        if not self.api_keys:
            raise ValueError("At least one OPENAI_API_KEY environment variable is required")
        
        logger.info(f"ðŸš€ MULTI-API KEY SYSTEM: {len(self.api_keys)} API keys available for parallel processing!")
        
        # Optional sharding configuration (HTTP fan-out to peer workers)
        self.sharding_enabled = os.environ.get('SHARDING_ENABLED', 'false').lower() == 'true'
        self.max_workers_per_scan = int(os.environ.get('SHARD_MAX_WORKERS_PER_SCAN', '3'))
        peers_raw = os.environ.get('WORKER_PEERS', '')
        # Comma-separated list of base URLs, e.g., https://service-1.run.app,https://service-2.run.app
        self.worker_peers = [p.strip().rstrip('/') for p in peers_raw.split(',') if p.strip()]
        self.worker_auth_token = os.environ.get('WORKER_AUTH_TOKEN', '')
        if self.sharding_enabled:
            logger.info(f"ðŸ§© Sharding enabled. Peers: {len(self.worker_peers)}, max_workers_per_scan={self.max_workers_per_scan}")
        
        # Initialize token usage tracking
        self.total_tokens_used = 0
        self.prompt_tokens = 0
        self.completion_tokens = 0
        self.api_calls_made = 0
        
        # ðŸš€ DEPENDENCY ANALYSIS SYSTEM: Eliminate false positives
        self.dependency_analyzer = DependencyAnalyzer()
        self.framework_detector = FrameworkDetector()
        self.false_positive_filter = FalsePositiveFilter()
        self.evidence_filter = EvidenceFilter()
        
        # PHASE 4: Caching and ML-based optimization
        self.result_cache = {}  # Cache for analysis results
        self.pattern_database = {}  # Database of known security patterns
        self.file_risk_scores = {}  # Risk scores for files based on previous scans
        
        # ðŸš€ ADVANCED CACHING SYSTEM: Multi-level intelligent caching
        self.cache_stats = {
            'hits': 0,
            'misses': 0,
            'total_requests': 0,
            'cache_size': 0,
            'memory_usage_mb': 0
        }
        
        # Multi-level cache system
        self.file_cache = OrderedDict()  # LRU cache for file analysis results
        self.pattern_cache = OrderedDict()  # LRU cache for security patterns
        self.batch_cache = OrderedDict()  # LRU cache for batch analysis
        self.code_snippet_cache = OrderedDict()  # LRU cache for code snippets
        
        # Cache configuration
        self.max_cache_size = 10000  # Maximum number of cached items
        self.cache_ttl_hours = 24  # Cache items expire after 24 hours
        self.pattern_similarity_threshold = 0.85  # Similarity threshold for pattern matching
        
        # Cache cleanup
        self.last_cache_cleanup = time.time()
        self.cache_cleanup_interval = 3600  # Clean up every hour
        
                # Progress tracking - will be set by the main worker
        self.progress_tracker = None
        
        # Security categories for comprehensive coverage
        
        # Security categories for comprehensive coverage
        self.security_categories = [
            "Authentication & Authorization",
            "Input Validation & Injection",
            "Data Exposure & Privacy",
            "Cryptography & Secrets Management",
            "Session Management",
            "File Upload Security",
            "API Security",
            "Frontend Security (XSS, CSRF)",
            "Backend Security (SQL Injection, etc.)",
            "Business Logic Flaws",
            "Error Handling & Information Disclosure",
            "Dependency Vulnerabilities",
            "Configuration Security",
            "Network Security",
            "Physical Security (if applicable)"
        ]
        
        # Indie developer specific security patterns
        self.indie_security_patterns = [
            "Hardcoded API keys in frontend",
            "Missing authentication checks",
            "Insecure default configurations",
            "Exposed environment variables",
            "Weak password policies",
            "Missing rate limiting",
            "Insecure file uploads",
            "SQL injection vulnerabilities",
            "XSS in user inputs",
            "Missing HTTPS enforcement",
            "Weak session management",
            "Exposed debug endpoints",
            "Missing input validation",
            "Insecure OAuth flows",
            "Weak encryption usage",
            "Missing security headers",
            "Exposed error messages",
            "Insecure deserialization",
            "Missing access controls",
            "Weak crypto implementations"
        ]
        
        # Support up to 4 API keys per worker (5 workers Ã— 4 keys = 20 total)
        for i in range(1, 5):
            additional_key = os.environ.get(f'OPENAI_API_KEY_{i}')
            if additional_key:
                self.api_keys.append(additional_key)
        
        # Sharding configuration
        self.sharding_enabled = os.environ.get('SHARDING_ENABLED', 'false').lower() == 'true'
        self.worker_peers = os.environ.get('WORKER_PEERS', '').split(',') if os.environ.get('WORKER_PEERS') else []
        self.max_shard_workers = 2  # Max 2 workers collaborate on sharding
        self.min_files_for_sharding = 300  # Only shard repos with 300+ files
    
    def set_progress_tracker(self, progress_tracker):
        """Set the progress tracker instance for this scanner"""
        self.progress_tracker = progress_tracker
        logger.info(f"ðŸ”— PROGRESS TRACKER CONNECTED: Scanner now has access to progress tracking")
    
    # Progress callback methods completely removed
    
    async def clone_repository(self, repo_url: str, github_token: str = None) -> str:
        """Clone repository with authentication"""
        logger.info(f"ðŸ“¥ Cloning repository: {repo_url}")
        
        # Progress tracking removed
        
        # Validate repository URL
        if not any(domain in repo_url for domain in ALLOWED_REPO_DOMAINS):
            raise ValueError(f"Repository domain not allowed. Allowed: {ALLOWED_REPO_DOMAINS}")
        
        # Create temporary directory
        temp_dir = tempfile.mkdtemp()
        repo_name = repo_url.split('/')[-1].replace('.git', '')
        repo_path = os.path.join(temp_dir, repo_name)
        
        logger.info(f"ðŸ“ Temp directory: {temp_dir}")
        logger.info(f"ðŸ“ Repository path: {repo_path}")
        
        try:
            # Build clone command with MAXIMUM speed optimization
            if github_token:
                # Use token for private repos
                auth_url = repo_url.replace('https://', f'https://{github_token}@')
                clone_cmd = ['git', 'clone', '--single-branch', '--depth', '1', '--no-tags', '--shallow-submodules', auth_url, repo_path]
                logger.info(f"ðŸ” Using authenticated clone for private repo (optimized)")
            else:
                clone_cmd = ['git', 'clone', '--single-branch', '--depth', '1', '--no-tags', '--shallow-submodules', repo_url, repo_path]
                logger.info(f"ðŸŒ Using public clone (optimized)")
            
            # Mask sensitive tokens in logged clone command
            masked_cmd = ' '.join(clone_cmd)
            if github_token:
                masked_cmd = masked_cmd.replace(github_token, '***')
            logger.info(f"ðŸš€ Clone command: {masked_cmd}")
            
            # Execute clone
            process = await asyncio.create_subprocess_exec(
                *clone_cmd,
                stdout=asyncio.subprocess.PIPE,
                stderr=asyncio.subprocess.PIPE
            )
            
            logger.info(f"â³ Cloning in progress...")
            stdout, stderr = await asyncio.wait_for(process.communicate(), timeout=300)
            
            if process.returncode != 0:
                error_msg = stderr.decode()
                if github_token:
                    error_msg = error_msg.replace(github_token, '***')
                logger.error(f"âŒ Git clone failed with return code {process.returncode}")
                logger.error(f"âŒ Error output: {error_msg}")
                raise Exception(f"Git clone failed: {error_msg}")
            
            # Validate cloned repository
            if not os.path.exists(repo_path):
                raise Exception("Repository directory not created after clone")
            
            # Get repository size and file count
            repo_size = self.get_directory_size(repo_path)
            file_count = self.count_files(repo_path)
            
            logger.info(f"âœ… Repository cloned successfully: {repo_path}")
            logger.info(f"ðŸ“Š Repository size: {repo_size}")
            logger.info(f"ðŸ“Š Total files: {file_count}")
            
                    # Progress tracking removed
            
            return repo_path
            
        except Exception as e:
            # Cleanup on failure
            logger.error(f"âŒ Clone failed: {e}")
            shutil.rmtree(temp_dir, ignore_errors=True)
            raise e
    
    async def analyze_file_async(self, file_path: str, relative_path: str, file_type: str) -> List[SecurityFinding]:
        """Async wrapper for file analysis"""
        try:
            # Get file size
            file_size = os.path.getsize(file_path)
            if file_size > 1024 * 1024:  # 1MB
                logger.warning(f"âš ï¸ File {relative_path} is large ({file_size/1024/1024:.1f}MB), may take longer to analyze")
            
            with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                content = f.read()
            
            logger.info(f"ðŸ“„ File {relative_path}: {len(content)} characters")
            
            # Analyze with ChatGPT
            findings = self.analyze_file_with_chatgpt(relative_path, content, file_type)
            return findings
            
        except Exception as e:
            logger.warning(f"âŒ Failed to analyze {relative_path}: {e}")
            return []

    def analyze_file_with_chatgpt(self, file_path: str, file_content: str, file_type: str) -> List[SecurityFinding]:
        """Analyze a single file with ChatGPT for security vulnerabilities"""
        try:
            # ðŸš€ ADVANCED CACHING: Check cache first before expensive analysis
            cached_result = self.get_cached_result(file_content, "file")
            if cached_result:
                logger.info(f"ðŸŽ¯ CACHE HIT: Using cached analysis for {file_path}")
                return cached_result
            
            # Get file-specific analysis rules
            analysis_rules = self.get_file_analysis_rules(file_path)
            
            # ðŸš€ LANGUAGE-SPECIFIC SECURITY ANALYSIS: Tailored for each programming language
            language_context = self.get_language_security_context(file_type, file_path)
            
            # Build UNIVERSAL context-aware security analysis prompt for ALL tech stacks
            prompt = f"""
            You are an expert security engineer analyzing a {file_type} file in a modern web application.

            FILE: {file_path}
            CONTENT:
            {file_content}

            {language_context}

            APPLICATION CONTEXT:
            - This is a modern web application (could be Next.js, Nuxt, Vue, React, Svelte, Angular, etc.)
            - Uses modern authentication (OAuth, JWT, session-based, etc.)
            - Has a backend (could be Firebase, Supabase, MongoDB, PostgreSQL, MySQL, etc.)
            - Built for indie developers, solopreneurs, and small teams

            CRITICAL: IGNORE THESE FALSE POSITIVES (ALL PLATFORMS):
            - Environment variables with PUBLIC prefixes (NEXT_PUBLIC_, NUXT_PUBLIC_, VITE_PUBLIC_, etc.)
            - OAuth client IDs, redirect URIs (PUBLIC by design - not secrets)
            - Database configuration keys (PUBLIC by design - not secrets)
            - Build-time environment access patterns
            - Public API endpoints that are meant to be accessible
            - Configuration files with intentionally public values
            - Component props and UI configuration
            - Package.json dependencies and metadata
            - Framework configuration files

            FOCUS ON REAL SECURITY VULNERABILITIES:
            - XSS in user input rendering (dangerouslySetInnerHTML, user input in DOM)
            - SQL injection in database queries (user input in SQL)
            - CSRF in state-changing operations (POST/PUT/DELETE without tokens)
            - Authentication bypasses (missing auth checks, weak validation)
            - Insecure file upload handling (no file type validation, path traversal)
            - Exposed sensitive endpoints (admin routes, internal APIs)
            - Weak password policies (no complexity requirements)
            - Session fixation attacks (predictable session IDs)
            - Information disclosure (error messages, stack traces)
            - Insecure deserialization (user input in eval, JSON.parse)
            - Dependency vulnerabilities (outdated packages with known CVEs)
            - Insecure default configurations

            ANALYSIS RULES:
            1. Only report ACTUAL security vulnerabilities, not configuration patterns
            2. Focus on code that processes user input or handles sensitive operations
            3. Look for missing security controls (auth, validation, sanitization)
            4. Consider the real-world impact on the application
            5. Be practical - focus on risks that indie developers actually face
            6. Ignore findings about intentionally public configuration values
            7. **Use language-specific security knowledge for accurate analysis**

            Return findings in this exact JSON format:
            {{
                "findings": [
                    {{
                        "rule_id": "vulnerability_type_identifier",
                        "severity": "Critical|High|Medium|Low",
                        "message": "Brief vulnerability description",
                        "description": "Detailed explanation",
                        "file_path": "{file_path}",
                        "line_number": 123,
                        "end_line": 125,
                        "code_snippet": "vulnerable code here",
                        "cwe_ids": ["CWE-79", "CWE-89"],
                        "owasp_ids": ["A01:2021", "A03:2021"],
                        "impact": "High|Medium|Low",
                        "likelihood": "High|Medium|Low",
                        "confidence": "High|Medium|Low"
                    }}
                ]
            }}
            
            IMPORTANT: 
            - For rule_id, use descriptive identifiers like "xss_vulnerability", "sql_injection", "csrf_missing"
            - Only report findings that represent REAL security risks
            - If no actual vulnerabilities found, return empty findings array
            - Be thorough but practical for indie developer applications
            - This scanner works for ALL modern web frameworks and platforms
            - **Apply language-specific security knowledge for accurate analysis**
            """

            # MULTI-API KEY PARALLEL PROCESSING: Use round-robin API key selection
            api_key_index = self.api_calls_made % len(self.api_keys)
            selected_api_key = self.api_keys[api_key_index]
            
            # Call ChatGPT API
            client = openai.OpenAI(api_key=selected_api_key)
            response = client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "system", "content": "You are an expert security engineer focused on making indie developer applications bulletproof."},
                    {"role": "user", "content": prompt}
                ],
                max_tokens=4000,
                temperature=0.1
            )
            
            # Track token usage
            self.api_calls_made += 1
            if hasattr(response, 'usage') and response.usage:
                self.prompt_tokens += response.usage.prompt_tokens
                self.completion_tokens += response.usage.completion_tokens
                self.total_tokens_used += response.usage.total_tokens
                logger.info(f"ðŸ” Token usage for {file_path}: {response.usage.total_tokens} tokens (prompt: {response.usage.prompt_tokens}, completion: {response.usage.completion_tokens})")
            else:
                logger.warning(f"âš ï¸ No token usage data available for {file_path}")
            
            # Parse response
            content = response.choices[0].message.content
            logger.info(f"ðŸ” ChatGPT response for {file_path}: {content[:200]}...")
            
            try:
                # Try to extract JSON from the response
                # Look for JSON blocks in markdown or text
                json_start = content.find('{')
                json_end = content.rfind('}') + 1
                
                if json_start != -1 and json_end > json_start:
                    json_content = content[json_start:json_end]
                    result = json.loads(json_content)
                    findings = result.get('findings', [])
                    
                    # Convert to SecurityFinding objects with UNIQUE rule_ids
                    security_findings = []
                    for i, finding in enumerate(findings):
                        try:
                            # Ensure unique rule_id by adding file identifier and counter
                            file_id = os.path.basename(file_path).replace('.', '_').replace('-', '_')
                            unique_rule_id = f"{finding.get('rule_id', 'vulnerability')}_{file_id}_{i+1}"
                            
                            # Create finding with unique rule_id
                            finding_data = finding.copy()
                            finding_data['rule_id'] = unique_rule_id
                            # Force file_path to the actual analyzed file to avoid invalid paths
                            finding_data['file_path'] = file_path
                            
                            security_findings.append(SecurityFinding(**finding_data))
                        except Exception as e:
                            logger.warning(f"Failed to create SecurityFinding for {file_path}: {e}")
                            continue
                    
                    logger.info(f"âœ… Successfully parsed {len(security_findings)} findings for {file_path}")
                    
                    # ðŸš€ ADVANCED CACHING: Cache the analysis result for future use
                    self.cache_result(file_content, security_findings, "file")
                    
                    # Also cache as a pattern for similar files
                    normalized_content = self.normalize_code_content(file_content)
                    pattern_cache_entry = {
                        'data': security_findings,
                        'original_content': normalized_content,
                        'timestamp': time.time(),
                        'size': len(str(security_findings)),
                        'type': 'pattern'
                    }
                    pattern_key = self.generate_cache_key(normalized_content, "pattern")
                    self._add_to_lru_cache(self.pattern_cache, pattern_key, pattern_cache_entry)
                    
                    return security_findings
                else:
                    logger.warning(f"No JSON found in ChatGPT response for {file_path}")
                    return []
                    
            except json.JSONDecodeError as e:
                logger.warning(f"Failed to parse ChatGPT response for {file_path}: {e}")
                logger.warning("Response content omitted for security")
                return []
            except Exception as e:
                logger.error(f"Unexpected error parsing response for {file_path}: {e}")
                return []
                
        except Exception as e:
            logger.error(f"Error analyzing {file_path} with ChatGPT: {e}")
            return []
    
    def condense_findings(self, findings: List[SecurityFinding]) -> List[SecurityFinding]:
        """Condense multiple similar findings into one with occurrence count"""
        # First, filter out false positives
        filtered_findings = self.filter_false_positives(findings)
        
        condensed = {}
        condensed_counter = 1  # Counter for unique condensed finding IDs
        
        for finding in filtered_findings:
            # Create a key based on vulnerability TYPE and severity, not specific rule_id
            # Extract the vulnerability type from the message (e.g., "XSS", "CSRF", "SQL Injection")
            vulnerability_type = self.extract_vulnerability_type(finding.message)
            key = f"{vulnerability_type}_{finding.severity}"
            
            if key in condensed:
                # Increment occurrence count
                condensed[key].occurrences += 1
                # Update the file_path to show multiple locations
                if finding.file_path not in condensed[key].file_path:
                    condensed[key].file_path += f", {finding.file_path}"
            else:
                # Create a NEW finding with a unique rule_id for React keys
                unique_finding = SecurityFinding(
                    rule_id=f"CONDENSED_{condensed_counter}_{vulnerability_type}",
                    severity=finding.severity,
                    message=finding.message,
                    description=finding.description,
                    file_path=finding.file_path,
                    line_number=finding.line_number,
                    end_line=finding.end_line,
                    code_snippet=finding.code_snippet,
                    cwe_ids=finding.cwe_ids,
                    owasp_ids=finding.owasp_ids,
                    impact=finding.impact,
                    likelihood=finding.likelihood,
                    confidence=finding.confidence,
                    occurrences=1
                )
                condensed[key] = unique_finding
                condensed_counter += 1
        
        return list(condensed.values())

    def filter_false_positives(self, findings: List[SecurityFinding]) -> List[SecurityFinding]:
        """Universal false positive filtering system for ALL tech stacks"""
        if not findings:
            return []
        
        filtered = []
        false_positive_count = 0
        
        # UNIVERSAL false positive patterns for ALL tech stacks
        universal_false_positive_patterns = [
            # Environment Variables (ALL platforms)
            'next_public_', 'nuxt_public_', 'vite_public_', 'svelte_public_',
            'process.env.public', 'import.meta.env.public', 'window.env.public',
            'public environment', 'public config', 'public variable',
            
            # OAuth & Authentication (ALL platforms)
            'client id', 'client_id', 'redirect uri', 'redirect_uri',
            'oauth config', 'auth config', 'public oauth', 'public auth',
            'github client', 'google client', 'facebook client', 'discord client',
            
            # Database Configuration (ALL platforms)
            'supabase config', 'firebase config', 'mongodb config', 'postgres config',
            'database config', 'db config', 'connection string', 'connection_string',
            'public database', 'public connection', 'public endpoint',
            
            # Build & Framework Config (ALL platforms)
            'webpack config', 'vite config', 'rollup config', 'esbuild config',
            'babel config', 'typescript config', 'tailwind config', 'postcss config',
            'next config', 'nuxt config', 'svelte config', 'vue config',
            'angular config', 'react config', 'ember config',
            
            # Component & UI (ALL frameworks)
            'component props', 'component configuration', 'ui config', 'ui configuration',
            'public props', 'public interface', 'public component', 'public ui',
            'theme config', 'style config', 'css config', 'design system',
            
            # API & Service Configuration (ALL platforms)
            'api config', 'service config', 'endpoint config', 'route config',
            'public api', 'public service', 'public endpoint', 'public route',
            'stripe config', 'paypal config', 'aws config', 'azure config',
            
            # General Configuration Files (ALL platforms)
            'config file', 'configuration file', 'setup file', 'initialization file',
            'package.json', 'composer.json', 'requirements.txt', 'gemfile',
            'cargo.toml', 'go.mod', 'pom.xml', 'build.gradle',
            
            # Documentation & Build Artifacts
            'readme', 'changelog', 'license', 'contributing',
            'build output', 'dist folder', 'out folder', 'coverage report',
            
            # Development Tools (ALL platforms)
            'eslint config', 'prettier config', 'stylelint config', 'husky config',
            'lint staged', 'commitlint', 'jest config', 'vitest config',
            'cypress config', 'playwright config', 'storybook config'
        ]
        
        for finding in findings:
            # Check if finding matches universal false positive patterns
            finding_text = f"{finding.message.lower()} {finding.description.lower()}"
            
            is_false_positive = False
            for pattern in universal_false_positive_patterns:
                if pattern in finding_text:
                    is_false_positive = True
                    false_positive_count += 1
                    logger.info(f"ðŸ” UNIVERSAL FILTER: Filtered false positive: {finding.message[:100]}...")
                    break
            
            if not is_false_positive:
                filtered.append(finding)
        
        logger.info(f"âœ… UNIVERSAL False positive filtering: {len(findings)} â†’ {len(filtered)} findings (filtered {false_positive_count})")
        return filtered

    def is_false_positive_finding(self, finding: SecurityFinding, file_path: str) -> bool:
        """Universal false positive detection for ALL tech stacks"""
        file_path_lower = file_path.lower()
        finding_text = f"{finding.message.lower()} {finding.description.lower()}"
        
        # Database & Backend files (ALL platforms) - ignore public config findings
        if any(term in file_path_lower for term in [
            'firebase', 'supabase', 'mongodb', 'postgres', 'mysql', 'sqlite',
            'prisma', 'sequelize', 'typeorm', 'drizzle', 'knex'
        ]):
            if any(term in finding_text for term in [
                'next_public', 'nuxt_public', 'vite_public', 'svelte_public',
                'database config', 'db config', 'connection string', 'public database'
            ]):
                return True
        
        # OAuth & Authentication files (ALL platforms) - ignore OAuth config findings
        elif any(term in file_path_lower for term in [
            'oauth', 'auth', 'github', 'google', 'facebook', 'discord', 'twitter',
            'login', 'register', 'signin', 'signup', 'authentication'
        ]):
            if any(term in finding_text for term in [
                'client id', 'client_id', 'oauth config', 'redirect uri', 'public oauth'
            ]):
                return True
        
        # Configuration & Build files (ALL platforms) - ignore config findings
        elif any(term in file_path_lower for term in [
            'config', 'env', 'setup', 'webpack', 'vite', 'rollup', 'esbuild',
            'babel', 'typescript', 'tailwind', 'postcss', 'eslint', 'prettier'
        ]):
            if any(term in finding_text for term in [
                'environment', 'config file', 'build config', 'framework config'
            ]):
                return True
        
        # Frontend Component files (ALL frameworks) - ignore UI config findings
        elif any(term in file_path_lower for term in [
            'component', 'page', 'ui', 'view', 'screen', 'layout',
            'react', 'vue', 'svelte', 'angular', 'ember', 'next', 'nuxt'
        ]):
            if any(term in finding_text for term in [
                'component props', 'ui config', 'public props', 'theme config'
            ]):
                return True
        
        # Package & Dependency files (ALL platforms) - ignore package findings
        elif any(term in file_path_lower for term in [
            'package.json', 'composer.json', 'requirements.txt', 'gemfile',
            'cargo.toml', 'go.mod', 'pom.xml', 'build.gradle', 'yarn.lock'
        ]):
            if any(term in finding_text for term in [
                'dependency list', 'package list', 'version info', 'license info'
            ]):
                return True
        
        return False
    
    def extract_vulnerability_type(self, message: str) -> str:
        """Extract vulnerability type from message for grouping"""
        message_lower = message.lower()
        
        # Define vulnerability type patterns
        if any(xss_term in message_lower for xss_term in ['xss', 'cross-site scripting', 'script injection']):
            return 'xss_vulnerability'
        elif any(csrf_term in message_lower for csrf_term in ['csrf', 'cross-site request forgery']):
            return 'csrf_vulnerability'
        elif any(sql_term in message_lower for sql_term in ['sql injection', 'sql injection', 'database injection']):
            return 'sql_injection'
        elif any(auth_term in message_lower for auth_term in ['authentication', 'authorization', 'auth bypass']):
            return 'authentication_vulnerability'
        elif any(input_term in message_lower for input_term in ['input validation', 'unsanitized input', 'user input']):
            return 'input_validation_vulnerability'
        elif any(secret_term in message_lower for secret_term in ['secret', 'api key', 'password', 'token']):
            return 'secrets_exposure'
        elif any(dep_term in message_lower for dep_term in ['dependency', 'outdated', 'vulnerable package']):
            return 'dependency_vulnerability'
        elif any(target_term in message_lower for target_term in ['target="_blank"', 'tabnabbing']):
            return 'insecure_target_blank'
        elif any(error_term in message_lower for error_term in ['error handling', 'information disclosure', 'sensitive information']):
            return 'information_disclosure'
        else:
            # Fallback: use first few words of message
            words = message.split()
            return '_'.join(words[:3]).lower().replace('-', '_').replace('(', '').replace(')', '')
    
    def generate_condensed_remediations(self, condensed_findings: List[SecurityFinding], all_findings: List[SecurityFinding], scan_context: Dict[str, Any] = None) -> Dict[str, str]:
        """Generate ALL remediation prompts in ONE API call - MASSIVE optimization!"""
        try:
            logger.info(f"ðŸš€ NUCLEAR OPTIMIZATION: Generating {len(condensed_findings)} remediations in ONE API call!")
            
            # Create ONE comprehensive prompt for ALL findings with file locations
            all_findings_summary = []
            for finding in condensed_findings:
                instances = [f for f in all_findings if f.rule_id == finding.rule_id]
                # Get all file paths and line numbers for this finding
                file_locations = []
                for instance in instances:
                    file_locations.append({
                        'file_path': instance.file_path,
                        'line_number': instance.line_number,
                        'end_line': instance.end_line
                    })
                
                all_findings_summary.append({
                    'rule_id': finding.rule_id,
                    'message': finding.message,
                    'severity': finding.severity,
                    'description': finding.description,
                    'cwe_ids': finding.cwe_ids,
                    'owasp_ids': finding.owasp_ids,
                    'occurrences': finding.occurrences,
                    'file_locations': file_locations
                })
            
            # ðŸš€ CONTEXT-AWARE ANALYSIS: Include framework and dependency context
            context_info = ""
            if scan_context:
                framework_info = scan_context.get('framework', {})
                dependency_info = scan_context.get('dependencies', {})
                
                context_info = f"""
                
                **FRAMEWORK & TECHNOLOGY CONTEXT** (Use this to provide framework-specific solutions):
                - Primary Framework: {framework_info.get('primary_framework', 'Unknown')}
                - Security Patterns Found: {', '.join(framework_info.get('security_patterns', []))}
                - Missing Security Measures: {', '.join(framework_info.get('missing_security', []))}
                - Package Manager: {dependency_info.get('package_manager', 'Unknown')}
                - Dependencies: {len(dependency_info.get('dependencies', {}))} packages
                - Framework-Specific Recommendations: {', '.join(framework_info.get('recommendations', []))}
                
                **ANALYSIS REQUIREMENTS**:
                - Consider the detected framework when suggesting solutions
                - Use framework-specific security patterns when available
                - Avoid suggesting solutions that conflict with the detected framework
                - Provide framework-appropriate code examples
                """
            
            # ONE MASSIVE PROMPT for ALL findings
            prompt = f"""
            You are an expert security engineer. Create remediation prompts for MULTIPLE security vulnerabilities in ONE response.
            
            VULNERABILITIES TO ANALYZE:
            {json.dumps(all_findings_summary, indent=2)}
            {context_info}
            
            **CRITICAL REQUIREMENT**: For each vulnerability, you MUST include:
            - The exact file path(s) affected
            - Specific line numbers where the vulnerability exists
            - Which pages/components are impacted
            - How many occurrences exist across the codebase
            - **Framework-specific solution** (based on detected technology stack)
            
            For EACH vulnerability, create a remediation prompt that:
            1. Clearly explains the security issue
            2. Provides context about why it's dangerous
            3. Gives specific, actionable steps to fix it
            4. Is written for coding assistants (Cursor, GitHub Copilot, etc.)
            5. Includes code examples appropriate for the detected framework
            6. Addresses the root cause, not just symptoms
            7. **ALWAYS mentions the specific files and line numbers affected**
            8. **Uses framework-specific security patterns when available**
            
            Example format for each remediation:
            ```
            **Critical: Missing Authorization Checks**
            - **Files Affected**: `src/app/dashboard/page.tsx` (lines 45-67), `src/components/auth/requireAuth.tsx` (lines 23-45)
            - **Pages Impacted**: Dashboard page, User settings page
            - **Occurrences**: Found in 3 files across the codebase
            - **Framework Context**: Next.js application (detected)
            - **Framework-Specific Fix**: Implement middleware.ts for authentication and use next-auth
            - **Action**: Add authorization checks before accessing sensitive resources
            ```
            
            Return in this EXACT JSON format:
            {{
                "remediations": {{
                    "rule_id_1": "remediation prompt text here",
                    "rule_id_2": "remediation prompt text here",
                    ...
                }}
            }}
            
            Make each prompt specific enough that a coding assistant can implement the fix robustly.
            **IMPORTANT**: Every remediation must include the exact file paths, line numbers, and framework-specific solutions.
            """
            
            # MULTI-API KEY PARALLEL PROCESSING: Use round-robin API key selection
            api_key_index = self.api_calls_made % len(self.api_keys)
            selected_api_key = self.api_keys[api_key_index]
            
            # ONE API CALL for ALL remediations
            client = openai.OpenAI(api_key=selected_api_key)
            response = client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "system", "content": "You are an expert security engineer creating multiple remediation prompts efficiently."},
                    {"role": "user", "content": prompt}
                ],
                max_tokens=6000,  # Increased for multiple prompts
                temperature=0.1
            )
            
            # Track token usage
            self.api_calls_made += 1
            if hasattr(response, 'usage') and response.usage:
                self.prompt_tokens += response.usage.prompt_tokens
                self.completion_tokens += response.usage.completion_tokens
                self.total_tokens_used += response.usage.total_tokens
                logger.info(f"ðŸš€ NUCLEAR OPTIMIZATION: Generated {len(condensed_findings)} remediations in 1 API call! Tokens: {response.usage.total_tokens}")
            else:
                logger.warning(f"âš ï¸ No token usage data available for nuclear optimization")
            
            # Parse the response
            content = response.choices[0].message.content
            try:
                json_start = content.find('{')
                json_end = content.rfind('}') + 1
                
                if json_start != -1 and json_end > json_start:
                    json_content = content[json_start:json_end]
                    result = json.loads(json_content)
                    remediations = result.get('remediations', {})
                    
                    logger.info(f"âœ… Successfully parsed {len(remediations)} remediations from nuclear optimization")
                    return remediations
                else:
                    logger.error("âŒ No JSON found in nuclear optimization response")
                    return {}
                    
            except json.JSONDecodeError as e:
                logger.error(f"âŒ Failed to parse nuclear optimization response: {e}")
                logger.error("Response content omitted for security")
                return {}
            
        except Exception as e:
            logger.error(f"âŒ Nuclear optimization failed: {e}")
            return {}

    
    
    def calculate_codebase_health(self, condensed_findings: List[SecurityFinding], all_findings: List[SecurityFinding], repo_info: Dict[str, Any]) -> int:
         """Calculate accurate codebase health percentage using reliable algorithm"""
         try:
             logger.info(f"ðŸ” Calculating codebase health for {len(condensed_findings)} condensed findings")
             
             # Group findings by severity
             critical = [f for f in condensed_findings if f.severity == "Critical"]
             high = [f for f in condensed_findings if f.severity == "High"]
             medium = [f for f in condensed_findings if f.severity == "Medium"]
             low = [f for f in condensed_findings if f.severity == "Low"]
             
             # Use the reliable fallback calculation instead of ChatGPT
             # This ensures consistent, accurate results without API failures
             health = self.calculate_fallback_health(critical, high, medium, low)
             
             logger.info(f"âœ… Calculated health percentage: {health}%")
             logger.info(f"ðŸ“Š Health breakdown: Critical={len(critical)}, High={len(high)}, Medium={len(medium)}, Low={len(low)}")
             
             return health
             
         except Exception as e:
             logger.error(f"âŒ Health calculation failed: {e}")
             logger.warning(f"âš ï¸ Using emergency fallback health calculation")
             return 50  # Emergency fallback
    
    def calculate_fallback_health(self, critical: List[SecurityFinding], high: List[SecurityFinding], medium: List[SecurityFinding], low: List[SecurityFinding]) -> int:
         """Fallback health calculation if ChatGPT fails"""
         try:
             # Start with 100%
             health = 100
             
             # Apply penalties based on severity
             health -= len(critical) * 15  # Critical: -15% each
             health -= len(high) * 8       # High: -8% each
             health -= len(medium) * 4     # Medium: -4% each
             health -= len(low) * 1        # Low: -1% each
             
             # Ensure health is within valid range
             health = max(0, min(100, health))
             
             logger.info(f"ðŸ“Š Fallback health calculation: {health}%")
             return health
             
         except Exception as e:
             logger.error(f"âŒ Fallback health calculation failed: {e}")
             return 50  # Default to 50% if everything fails
    
    async def scan_repository(self, repo_url: str, github_token: str = None) -> Dict[str, Any]:
        """Main method to scan repository for security vulnerabilities"""
        start_time = datetime.now()
        logger.info(f"ðŸš€ Starting ChatGPT security scan for: {repo_url}")
        
        try:
            # Progress tracking - now properly connected
            if self.progress_tracker:
                self.progress_tracker.update_progress("Cloning repository...", 5)
            
            # Clone repository with timeout
            repo_path = await asyncio.wait_for(
                self.clone_repository(repo_url, github_token), 
                timeout=600  # 10 minutes for cloning
            )
            
            # Get repository info
            repo_info = {
                'name': repo_path.split('/')[-1],
                'url': repo_url,
                'size': self.get_directory_size(repo_path),
                'file_count': self.count_files(repo_path)
            }
            
            # Progress update for dependency analysis
            if self.progress_tracker:
                self.progress_tracker.update_progress("Analyzing dependencies...", 10)
            
            # ðŸš€ DEPENDENCY ANALYSIS: Eliminate false positives about unused packages
            logger.info("ðŸ” DEPENDENCY ANALYSIS: Starting comprehensive dependency analysis...")
            
            try:
                # Analyze dependencies to eliminate false positives
                dependency_analysis = self.dependency_analyzer.analyze_dependencies(repo_path)
                logger.info(f"ðŸ” DEPENDENCY ANALYSIS: Package manager detected: {dependency_analysis.get('package_manager', 'Unknown')}")
                logger.info(f"ðŸ” DEPENDENCY ANALYSIS: Framework detected: {dependency_analysis.get('framework_detected', 'Unknown')}")
                logger.info(f"ðŸ” DEPENDENCY ANALYSIS: Dependencies found: {len(dependency_analysis.get('dependencies', {}))}")
                logger.info(f"ðŸ” DEPENDENCY ANALYSIS: Imports found: {len(dependency_analysis.get('imports_found', {}))}")
                logger.info(f"ðŸ” DEPENDENCY ANALYSIS: Truly unused packages: {dependency_analysis.get('unused_packages', [])}")
                
                # Detect framework for context-aware analysis
                framework_analysis = self.framework_detector.detect_framework(repo_path)
                logger.info(f"ðŸ” FRAMEWORK DETECTION: Primary framework: {framework_analysis.get('primary_framework', 'Unknown')}")
                logger.info(f"ðŸ” FRAMEWORK DETECTION: Security patterns found: {framework_analysis.get('security_patterns', [])}")
                logger.info(f"ðŸ” FRAMEWORK DETECTION: Missing security: {framework_analysis.get('missing_security', [])}")
                
                # Store context for false positive filtering
                scan_context = {
                    'dependencies': dependency_analysis,
                    'framework': framework_analysis,
                    'repository_path': repo_path
                }
                
            except Exception as e:
                logger.warning(f"âš ï¸ Dependency analysis failed: {e}")
                scan_context = {}
            
            # Progress update for file analysis
            if self.progress_tracker:
                self.progress_tracker.update_progress("Starting file analysis...", 15)
            
            # PHASE 1 NUCLEAR OPTIMIZATION: Smart File Filtering + Batch Analysis
            all_findings = []
            
            # ðŸš€ MULTI-LANGUAGE SUPPORT: Support for all major programming languages and frameworks
            file_types = [
                # JavaScript/TypeScript Ecosystem
                '.js', '.ts', '.tsx', '.jsx', '.mjs', '.cjs',
                # Python Ecosystem
                '.py', '.pyx', '.pyi', '.pyw',
                # Go Ecosystem
                '.go', '.mod',
                # Rust Ecosystem
                '.rs', '.toml',
                # Java Ecosystem
                '.java', '.kt', '.gradle', '.xml',
                # C# Ecosystem
                '.cs', '.vb', '.csproj', '.vbproj',
                # PHP Ecosystem
                '.php', '.phtml', '.php3', '.php4', '.php5', '.php7',
                # Ruby Ecosystem
                '.rb', '.erb', '.rake', '.gemspec',
                # Web Technologies
                '.html', '.htm', '.xhtml', '.vue', '.svelte', '.jsx', '.tsx',
                # Configuration Files
                '.yaml', '.yml', '.json', '.toml', '.ini', '.conf', '.config',
                # Shell Scripts
                '.sh', '.bash', '.zsh', '.fish', '.ps1', '.bat', '.cmd',
                # Docker & Infrastructure
                '.dockerfile', '.dockerignore', '.yml', '.yaml',
                # Database
                '.sql', '.plsql', '.tsql'
            ]
            
            # Collect and filter files with smart prioritization
            files_to_analyze = []
            skipped_files = 0
            skipped_size = 0
            
            for root, dirs, files in os.walk(repo_path):
                dirs[:] = [d for d in dirs if d not in ['.git', 'node_modules', '__pycache__', '.venv', 'venv']]
                for file in files:
                    if any(file.endswith(ext) for ext in file_types):
                        file_path = os.path.join(root, file)
                        relative_path = os.path.relpath(file_path, repo_path)
                        file_size = os.path.getsize(file_path)
                        
                        # Apply smart file filtering
                        if self.should_skip_file(relative_path, file_size):
                            skipped_files += 1
                            skipped_size += file_size
                            continue
                        
                        files_to_analyze.append((file_path, relative_path, file))
            
            total_files = len(files_to_analyze)
            total_skipped = skipped_files
            
            logger.info(f"ðŸ” PHASE 1 NUCLEAR OPTIMIZATION: Smart file filtering complete!")
            logger.info(f"ðŸ” Files to analyze: {total_files} (was {total_files + total_skipped})")
            logger.info(f"ðŸ” Files skipped: {total_skipped} ({total_skipped/(total_files + total_skipped)*100:.1f}%)")
            logger.info(f"ðŸ” Size skipped: {skipped_size/1024/1024:.1f}MB")
            logger.info(f"ðŸ” Supported file types: {', '.join(file_types)}")
            
            # Progress tracking removed
            
            # Create intelligent file batches based on priority
            file_batches = self.create_file_batches(files_to_analyze)
            total_batches = len(file_batches)
            
            logger.info(f"ðŸš€ PHASE 1 NUCLEAR OPTIMIZATION: Created {total_batches} intelligent batches")
            logger.info(f"ðŸš€ Priority 1 (Critical): Small batches (3 files) for thorough analysis")
            logger.info(f"ðŸš€ Priority 2 (Important): Medium batches (5 files) for balanced analysis")
            logger.info(f"ðŸš€ Priority 3 (Low): Large batches (8 files) for quick analysis")
            logger.info(f"ðŸš€ Expected performance: 3-5x faster with batch analysis!")
            
            # Add overall scan timeout protection
            scan_start_time = datetime.now()
            max_scan_time = 900  # 15 minutes max
            
            # Progress tracking removed
            
            # ðŸš€ PHASE 5: TRUE PARALLEL PROCESSING WITH OPTIONAL SHARDING
            logger.info(f"ðŸš€ PHASE 5 PARALLEL PROCESSING: Starting {total_batches} batches")
            logger.info(f"ðŸš€ Using {len(self.api_keys)} API keys for intra-worker parallelism")

            # If sharding is enabled and we have peers, offload part of the batches via HTTP fan-out
            # Respect minimum file threshold to avoid sharding small repos
            if self.sharding_enabled and self.worker_peers and total_files >= getattr(self, 'min_files_for_sharding', 300):
                try:
                    logger.info("ðŸ§© Sharding: distributing batches to peers")
                    # Progress tracking removed
                    
                    shardable_batches = list(file_batches)
                    local_batches: List[List[tuple]] = []

                    # Determine how many peers to use for this scan (capped)
                    peer_urls = self.worker_peers[: self.max_workers_per_scan - 1]  # -1 to keep local worker

                    # Simple round-robin partitioning: assign every (n)th batch to a peer
                    partitions: Dict[str, List[List[tuple]]] = {u: [] for u in peer_urls}
                    if peer_urls:
                        for idx, batch in enumerate(shardable_batches):
                            target_peer = peer_urls[idx % len(peer_urls)]
                            partitions[target_peer].append(batch)
                        # Keep a fair slice locally as well
                        local_batches = [b for i, b in enumerate(shardable_batches) if i % (len(peer_urls) + 1) == 0]
                    else:
                        local_batches = shardable_batches

                    # Fire-and-collect: send shards to peers asynchronously while processing local batches
                    aggregated_findings: List[SecurityFinding] = []

                    async def send_shard(peer_url: str, batches: List[List[tuple]]):
                        if not batches:
                            return []
                        # Build content payload per batch so peers don't need repo on disk
                        batches_payload: List[List[Dict[str, Any]]] = []
                        for batch in batches:
                            batches_payload.append(self._build_batch_payload(batch))
                        payload = {'batches_content': batches_payload}
                        headers = {'Content-Type': 'application/json'}
                        if self.worker_auth_token:
                            headers['Authorization'] = f"Bearer {self.worker_auth_token}"
                        async with aiohttp.ClientSession() as session:
                            async with session.post(f"{peer_url}/internal/shard-scan", json=payload, headers=headers, timeout=900) as resp:
                                if resp.status != 200:
                                    text = await resp.text()
                                    logger.warning(f"ðŸ§© Shard to {peer_url} failed: {resp.status}: {text[:200]}")
                                    return []
                                data = await resp.json()
                                return data.get('findings', [])

                    # Kick off peer shard requests
                    shard_tasks = [send_shard(url, batches) for url, batches in partitions.items()]

                    # Process local batches with existing thread pool flow while peers run
                    local_findings = self._process_batches_locally(local_batches, total_batches, scan_start_time, max_scan_time)

                    # Collect peer results
                    try:
                        peer_results = await asyncio.gather(*shard_tasks, return_exceptions=True)
                        for r in peer_results:
                            if isinstance(r, Exception):
                                logger.warning(f"ðŸ§© Shard task error: {r}")
                            else:
                                for f in r:
                                    # Convert dicts to SecurityFinding where applicable
                                    try:
                                        aggregated_findings.append(SecurityFinding(**f))
                                    except Exception:
                                        pass
                    except Exception as e:
                        logger.warning(f"ðŸ§© Shard collection failed: {e}")

                    all_findings = local_findings + aggregated_findings
                except Exception as e:
                    logger.warning(f"ðŸ§© Sharding disabled due to runtime error: {e}. Falling back to local processing.")
                    all_findings = self._process_batches_locally(file_batches, total_batches, scan_start_time, max_scan_time)
            else:
                # No sharding: process all batches locally
                all_findings = self._process_batches_locally(file_batches, total_batches, scan_start_time, max_scan_time)

            # all_findings already computed via local processing and/or sharding above
            
            # Progress tracking removed
            
            # Condense findings
            logger.info(f"ðŸ” Condensing {len(all_findings)} findings...")
            condensed_findings = self.condense_findings(all_findings)
            logger.info(f"âœ… Condensed to {len(condensed_findings)} unique findings")
            
            # ðŸš€ FALSE POSITIVE FILTERING: Eliminate false positives using context
            logger.info("ðŸ” FALSE POSITIVE FILTERING: Starting intelligent false positive filtering...")
            
            try:
                if 'scan_context' in locals() and scan_context:
                    original_count = len(condensed_findings)
                    condensed_findings = self.false_positive_filter.filter_findings(condensed_findings, scan_context)
                    filtered_count = len(condensed_findings)
                    eliminated_count = original_count - filtered_count
                    
                    logger.info(f"ðŸ” FALSE POSITIVE FILTERING: Eliminated {eliminated_count} false positives!")
                    logger.info(f"ðŸ” FALSE POSITIVE FILTERING: Original: {original_count} â†’ Filtered: {filtered_count}")
                    
                    if eliminated_count > 0:
                        logger.info("ðŸ” FALSE POSITIVE FILTERING: Eliminated findings were likely:")
                        logger.info("   - Unused package warnings (when packages are actually used)")
                        logger.info("   - Framework-handled security (when framework provides protection)")
                        logger.info("   - Development-only issues (console.log, debug mode)")
                        logger.info("   - Context-inappropriate warnings (wrong framework assumptions)")
                else:
                    logger.warning("âš ï¸ FALSE POSITIVE FILTERING: No scan context available, skipping filtering")
                    
            except Exception as e:
                logger.warning(f"âš ï¸ False positive filtering failed: {e}")
                logger.warning("âš ï¸ Continuing with unfiltered findings...")
            
            # Progress tracking removed
            
            # NUCLEAR OPTIMIZATION: Generate ALL remediations in ONE call
            logger.info(f"ðŸš€ NUCLEAR OPTIMIZATION: Generating {len(condensed_findings)} remediations in ONE API call...")
            start_time_remediations = datetime.now()
            condensed_remediations = self.generate_condensed_remediations(condensed_findings, all_findings, scan_context)
            remediation_time = (datetime.now() - start_time_remediations).total_seconds()
            logger.info(f"âœ… NUCLEAR OPTIMIZATION: Generated {len(condensed_remediations)} remediations in {remediation_time:.1f}s!")
            
            # Progress tracking removed
            
            # Master remediation removed
            
            # PROGRESS TRACKING: Calculate codebase health (EVEN DISTRIBUTION!)
            # Progress tracking removed
            
            # Progress update for health calculation
            if self.progress_tracker:
                self.progress_tracker.update_progress("Calculating codebase health...", 90)
            
            # Calculate accurate codebase health using ChatGPT
            logger.info(f"ðŸ” Calculating accurate codebase health...")
            codebase_health = self.calculate_codebase_health(condensed_findings, all_findings, repo_info)
            logger.info(f"âœ… Codebase health calculated: {codebase_health}%")
            
            # PROGRESS TRACKING: Health calculation complete (EVEN DISTRIBUTION!)
            # Progress tracking removed
            
            # Calculate scan duration
            scan_duration = (datetime.now() - start_time).total_seconds()
            
            # Calculate severity breakdown
            critical_count = len([f for f in condensed_findings if f.severity == "Critical"])
            high_count = len([f for f in condensed_findings if f.severity == "High"])
            medium_count = len([f for f in condensed_findings if f.severity == "Medium"])
            low_count = len([f for f in condensed_findings if f.severity == "Low"])
            
            logger.info(f"ðŸ“Š Severity breakdown:")
            logger.info(f"   ðŸ”´ Critical: {critical_count}")
            logger.info(f"   ðŸŸ  High: {high_count}")
            logger.info(f"   ðŸŸ¡ Medium: {medium_count}")
            logger.info(f"   ðŸŸ¢ Low: {low_count}")
            
            # Create security report
            report = SecurityReport(
                summary={
                    'total_findings': len(all_findings),
                    'condensed_findings': len(condensed_findings),
                    'critical_count': critical_count,
                    'high_count': high_count,
                    'medium_count': medium_count,
                    'low_count': low_count,
                    'codebase_health': codebase_health,
                    'files_scanned': repo_info['file_count'],
                    'scan_duration': scan_duration,
                    'gpt_api_usage': {
                        'total_api_calls': self.api_calls_made,
                        'prompt_tokens': self.prompt_tokens,
                        'completion_tokens': self.completion_tokens,
                        'total_tokens': self.total_tokens_used,
                        'estimated_cost_usd': round(self.total_tokens_used * 0.00000015, 4),
                        'tokens_per_file': round(self.total_tokens_used / max(1, total_files), 0),
                        'tokens_per_second': round(self.total_tokens_used / max(1, scan_duration), 0)
                    }
                },
                findings=all_findings,
                condensed_findings=condensed_findings,
                condensed_remediations=condensed_remediations,
                scan_duration=scan_duration,
                timestamp=datetime.now().isoformat(),
                repository_info=repo_info
            )
            
            # PROGRESS TRACKING: Final completion
            if self.progress_tracker:
                self.progress_tracker.update_progress("Finalizing results...", 95)
            
            # Cleanup
            shutil.rmtree(repo_path, ignore_errors=True)
            
            logger.info(f"âœ… Security scan completed in {scan_duration:.2f}s")
            logger.info(f"ðŸ“Š Found {len(all_findings)} total findings, {len(condensed_findings)} unique issues")
            logger.info(f"ðŸ“Š Files scanned: {repo_info['file_count']}")
            logger.info(f"ðŸ“Š Repository size: {repo_info['size']}")
            
            # Comprehensive token usage summary
            logger.info(f"ðŸ” GPT API Usage Summary:")
            logger.info(f"   ðŸ“ž Total API calls: {self.api_calls_made}")
            logger.info(f"   ðŸ“ Prompt tokens: {self.prompt_tokens:,}")
            logger.info(f"   âœï¸ Completion tokens: {self.completion_tokens:,}")
            logger.info(f"   ðŸŽ¯ Total tokens: {self.total_tokens_used:,}")
            logger.info(f"   ðŸ’° Estimated cost: ${self.total_tokens_used * 0.00000015:.4f} (GPT-4o-mini)")
            logger.info(f"   âš¡ Tokens per file: {self.total_tokens_used / max(1, total_files):.0f}")
            logger.info(f"   ðŸš€ Tokens per second: {self.total_tokens_used / max(1, scan_duration):.0f}")
            
            # Validate report structure
            if not isinstance(report.summary, dict):
                logger.error("âŒ Report summary is not a dictionary")
            if not isinstance(report.findings, list):
                logger.error("âŒ Report findings is not a list")
            if not isinstance(report.condensed_findings, list):
                logger.error("âŒ Report condensed_findings is not a list")
            
            logger.info(f"ðŸŽ¯ Report validation complete")
            logger.info(f"ðŸš€ Scan completed successfully in {scan_duration:.2f}s")
            
            # Final progress update
            if self.progress_tracker:
                self.progress_tracker.update_progress("Scan completed successfully!", 100)
            
            report_dict = asdict(report)
            try:
                if 'scan_context' in locals() and isinstance(scan_context, dict) and scan_context.get('vulnerable_packages'):
                    report_dict.setdefault('summary', {})
                    report_dict['summary']['vulnerable_packages'] = scan_context['vulnerable_packages']
            except Exception:
                pass
            
            # ðŸš€ ADD CACHE STATISTICS to scan result
            try:
                cache_stats = self.get_cache_statistics()
                report_dict['cache_statistics'] = cache_stats
                report_dict['cache_benefits'] = {
                    'cost_savings': f"${cache_stats.get('cache_hits', 0) * 0.02:.2f}",
                    'time_savings': f"{cache_stats.get('cache_hits', 0) * 0.5:.1f} minutes",
                    'hit_rate': f"{cache_stats.get('hit_rate_percent', 0)}%",
                    'api_calls_saved': cache_stats.get('cache_hits', 0)
                }
                logger.info(f"ðŸ“Š CACHE STATS: Scan completed with {cache_stats.get('hit_rate_percent', 0)}% cache hit rate")
            except Exception as cache_error:
                logger.warning(f"âš ï¸ Failed to get cache statistics: {cache_error}")
                report_dict['cache_statistics'] = {'error': 'Failed to retrieve cache statistics'}
            
            logger.info(f"âœ… Scan completed successfully in {scan_duration:.1f}s")
            
            return report_dict
            
        except Exception as e:
            logger.error(f"âŒ Security scan failed: {e}")
            # Cleanup on error
            if 'repo_path' in locals():
                shutil.rmtree(repo_path, ignore_errors=True)
            
            return {
                'error': str(e),
                'error_type': type(e).__name__,
                'scan_duration': (datetime.now() - start_time).total_seconds(),
                'timestamp': datetime.now().isoformat()
            }
    
    def get_directory_size(self, path: str) -> str:
        """Get directory size in human readable format"""
        total_size = 0
        for dirpath, dirnames, filenames in os.walk(path):
            for filename in filenames:
                filepath = os.path.join(dirpath, filename)
                if os.path.exists(filepath):
                    total_size += os.path.getsize(filepath)
        
        # Convert to MB
        size_mb = total_size / (1024 * 1024)
        return f"{size_mb:.1f}MB"
    
    def count_files(self, path: str) -> int:
        """Count total files in directory"""
        count = 0
        for root, dirs, files in os.walk(path):
            dirs[:] = [d for d in dirs if d not in ['.git', 'node_modules', '__pycache__', '.venv', 'venv']]
            count += len(files)
        return count

    def get_file_priority(self, file_path: str) -> int:
        """Determine file priority for scanning (1=Critical, 2=Important, 3=Low)"""
        relative_path = file_path.lower()
        
        # Priority 1: Critical security files (ALWAYS SCAN)
        if any(path in relative_path for path in [
            'src/app/', 'src/pages/', 'src/components/', 'src/auth/',
            'src/api/', 'src/db/', 'src/database/', 'src/models/',
            'src/controllers/', 'src/middleware/', 'src/routes/'
        ]):
            return 1
        
        # Priority 2: Important files (SCAN IF TIME ALLOWS)
        if any(path in relative_path for path in [
            'src/lib/', 'src/utils/', 'src/services/', 'src/helpers/',
            'src/types/', 'src/interfaces/', 'src/constants/'
        ]):
            return 2
        
        # Priority 3: Low priority (SKIP UNLESS FAST)
        return 3
    
    def should_skip_file(self, file_path: str, file_size: int) -> bool:
        """Determine if file should be skipped based on smart rules"""
        relative_path = file_path.lower()
        file_name = os.path.basename(file_path).lower()
        
        # Skip large files (>500KB)
        if file_size > 500 * 1024:
            return True
        
        # Skip config files
        if any(name in file_name for name in [
            'package.json', 'tsconfig.json', 'next.config', 'tailwind.config',
            'eslint.config', 'prettier.config', 'babel.config', 'webpack.config'
        ]):
            return True
        
        # Skip documentation
        if any(ext in file_name for ext in ['.md', '.txt', '.rst', '.adoc']):
            return True
        
        # Skip build artifacts
        if any(path in relative_path for path in [
            'dist/', 'build/', 'out/', '.next/', 'coverage/'
        ]):
            return True
        
        # Skip dependencies
        if any(path in relative_path for path in [
            'node_modules/', '.venv/', 'venv/', '__pycache__/'
        ]):
            return True
        
        # Skip test files
        if any(name in file_name for name in [
            '.test.', '.spec.', 'test_', 'spec_'
        ]):
            return True
        
        return False
    
    def create_file_batches(self, files_to_analyze: List[tuple]) -> List[List[tuple]]:
        """Create intelligent batches of files for analysis"""
        if not files_to_analyze:
            return []
        
        # Group files by priority first
        priority_1_files = []
        priority_2_files = []
        priority_3_files = []
        
        for file_path, relative_path, file_type in files_to_analyze:
            priority = self.get_file_priority(relative_path)
            if priority == 1:
                priority_1_files.append((file_path, relative_path, file_type))
            elif priority == 2:
                priority_2_files.append((file_path, relative_path, file_type))
            else:
                priority_3_files.append((file_path, relative_path, file_type))
        
        # Create batches: Priority 1 files get smaller batches for thorough analysis
        batches = []
        
        # Priority 1: Small batches (3 files) for thorough analysis
        for i in range(0, len(priority_1_files), 3):
            batch = priority_1_files[i:i+3]
            if batch:
                batches.append(batch)
        
        # Priority 2: Medium batches (5 files) for balanced analysis
        for i in range(0, len(priority_2_files), 5):
            batch = priority_2_files[i:i+5]
            if batch:
                batches.append(batch)
        
        # Priority 3: Large batches (8 files) for quick analysis
        for i in range(0, len(priority_3_files), 8):
            batch = priority_3_files[i:i+8]
            if batch:
                batches.append(batch)
        
        return batches

    def _process_batches_locally(self, batches: List[List[tuple]], total_batches: int, scan_start_time: datetime, max_scan_time: int) -> List['SecurityFinding']:
        """Process provided batches using the existing thread pool logic and return findings."""
        if not batches:
            return []
        import concurrent.futures
        from concurrent.futures import ThreadPoolExecutor, as_completed
        # Limit concurrent workers by available API keys to spread rate limit load
        max_workers = min(len(self.api_keys), len(batches), 4)
        logger.info(f"ðŸš€ THREAD POOL: Using {max_workers} concurrent workers for {len(batches)} local batches")
        start_parallel_time = datetime.now()
        all_findings: List[SecurityFinding] = []
        try:
            with ThreadPoolExecutor(max_workers=max_workers) as executor:
                future_to_batch: Dict[Any, int] = {}
                for batch_num, batch_files in enumerate(batches):
                    if batch_num > 0:
                        import time as _time
                        _time.sleep(0.1)
                    future = executor.submit(
                        self.analyze_files_batch_sync,
                        batch_files,
                        batch_num,
                        total_batches,
                        scan_start_time,
                        max_scan_time,
                    )
                    future_to_batch[future] = batch_num
                logger.info(f"ðŸš€ THREAD POOL: Submitted {len(future_to_batch)} batches for parallel execution")
                completed_batches = 0
                for future in as_completed(future_to_batch):
                    bnum = future_to_batch[future]
                    try:
                        batch_findings = future.result()
                        all_findings.extend(batch_findings)
                        completed_batches += 1
                        logger.info(f"âœ… THREAD POOL: Batch {bnum + 1} completed ({completed_batches}/{len(batches)}) - {len(batch_findings)} findings")
                    except Exception as e:
                        logger.error(f"âŒ THREAD POOL: Batch {bnum + 1} failed: {e}")
                        try:
                            logger.warning(f"âš ï¸ THREAD POOL: Attempting sequential fallback for batch {bnum + 1}")
                            fallback_findings = self.analyze_files_batch(batches[bnum])
                            all_findings.extend(fallback_findings)
                            logger.info(f"âœ… THREAD POOL: Sequential fallback successful for batch {bnum + 1}")
                        except Exception as fallback_error:
                            logger.error(f"âŒ THREAD POOL: Sequential fallback also failed for batch {bnum + 1}: {fallback_error}")
        except Exception as e:
            logger.error(f"âŒ Thread pool processing failed: {e}")
            logger.warning("âš ï¸ Falling back to sequential processing...")
            for batch_num, batch_files in enumerate(batches):
                try:
                    batch_findings = self.analyze_files_batch(batch_files)
                    all_findings.extend(batch_findings)
                except Exception as batch_error:
                    logger.error(f"âŒ Sequential fallback batch {batch_num + 1} failed: {batch_error}")
                    continue
        parallel_time = (datetime.now() - start_parallel_time).total_seconds()
        logger.info(f"ðŸš€ THREAD POOL COMPLETE: {len(batches)} local batches finished in {parallel_time:.1f}s!")
        logger.info(f"âœ… THREAD POOL: Total findings collected locally: {len(all_findings)}")
        return all_findings

    def _build_batch_payload(self, batch_files: List[tuple]) -> List[Dict[str, Any]]:
        """Read and truncate file contents to build a shardable payload.
        Each item: { 'file_path': relative_path, 'file_type': file_type, 'content': content }
        """
        payload_files: List[Dict[str, Any]] = []
        for file_path, relative_path, file_type in batch_files:
            try:
                with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                    content = f.read()
                # Truncate large contents similar to local analysis
                if len(content) > 12000:
                    chunks = self.chunk_file_content(content, relative_path, file_type)
                    if chunks:
                        content = chunks[0]
                    else:
                        content = content[:12000] + "\n... [truncated for shard analysis]"
                elif len(content) > 8000:
                    content = content[:8000] + "\n... [truncated for shard analysis]"
                payload_files.append({
                    'file_path': relative_path,
                    'file_type': file_type,
                    'content': content,
                })
            except Exception as e:
                logger.warning(f"âš ï¸ Failed to read {relative_path} for shard payload: {e}")
                continue
        return payload_files

    def analyze_files_batch_from_payload(self, batch_items: List[Dict[str, Any]], batch_num: int, total_batches: int, scan_start_time: datetime, max_scan_time: int) -> List['SecurityFinding']:
        """Analyze a batch where file contents are provided directly (used by shard workers)."""
        try:
            if not batch_items:
                return []
            elapsed_time = (datetime.now() - scan_start_time).total_seconds()
            if elapsed_time > max_scan_time - 60:
                logger.warning(f"âš ï¸ SHARD BATCH {batch_num + 1}: Approaching scan timeout ({elapsed_time:.0f}s), stopping early")
                return []
            batch_start_time = datetime.now()
            logger.info(f"ðŸ“¦ SHARD BATCH {batch_num + 1}/{total_batches} (files: {len(batch_items)}) - STARTING")
            
            # Update progress for shard batch processing
            try:
                if self.progress_tracker:
                    self.progress_tracker.update_progress(f"Shard batch {batch_num + 1}/{total_batches}", batch_num + 1)
                    logger.info(f"ðŸ“Š PROGRESS: Shard batch {batch_num + 1}/{total_batches} - Progress updated successfully")
                else:
                    logger.warning(f"âš ï¸ PROGRESS: No progress tracker available for shard batch {batch_num + 1}")
            except Exception as e:
                logger.error(f"âŒ PROGRESS ERROR: Failed to update progress for shard batch {batch_num + 1}: {e}")
                # Don't let progress tracking break the scan, but log the error

            batch_content = []
            for item in batch_items:
                content = item.get('content') or ''
                relative_path = item.get('file_path') or 'unknown'
                file_type = item.get('file_type') or 'unknown'
                if not content:
                    continue
                batch_content.append({
                    'file_path': relative_path,
                    'file_type': file_type,
                    'content': content,
                })
            if not batch_content:
                return []

            prompt = f"""
            You are an expert security engineer. Analyze MULTIPLE files for security vulnerabilities in ONE response.

            FILES TO ANALYZE:
            {json.dumps(batch_content, indent=2)}

            Return findings in this EXACT JSON format:
            {{
                "files": {{
                    "file_path_1": {{
                        "findings": [
                            {{
                                "rule_id": "vulnerability_type_identifier",
                                "severity": "Critical|High|Medium|Low",
                                "message": "Brief vulnerability description",
                                "description": "Detailed explanation",
                                "file_path": "file_path_1",
                                "line_number": 123,
                                "end_line": 125,
                                "code_snippet": "vulnerable code here",
                                "cwe_ids": ["CWE-79"],
                                "owasp_ids": ["A01:2021"],
                                "impact": "High|Medium|Low",
                                "likelihood": "High|Medium|Low",
                                "confidence": "High|Medium|Low"
                            }}
                        ]
                    }}
                }}
            }}
            """

            api_key_index = batch_num % len(self.api_keys)
            selected_api_key = self.api_keys[api_key_index]
            logger.info(f"ðŸš€ SHARD BATCH {batch_num + 1}: Using API key {api_key_index + 1}/{len(self.api_keys)}")
            max_retries = 3
            base_delay = 1.0
            for attempt in range(max_retries):
                try:
                    client = openai.OpenAI(api_key=selected_api_key)
                    response = client.chat.completions.create(
                        model="gpt-4o-mini",
                        messages=[
                            {"role": "system", "content": "You are an expert security engineer analyzing multiple files efficiently."},
                            {"role": "user", "content": prompt}
                        ],
                        max_tokens=8000,
                        temperature=0.1,
                    )
                    self.api_calls_made += 1
                    if hasattr(response, 'usage') and response.usage:
                        self.prompt_tokens += response.usage.prompt_tokens
                        self.completion_tokens += response.usage.completion_tokens
                        self.total_tokens_used += response.usage.total_tokens
                    content = response.choices[0].message.content
                    json_start = content.find('{')
                    json_end = content.rfind('}') + 1
                    if json_start != -1 and json_end > json_start:
                        result = json.loads(content[json_start:json_end])
                        files_data = result.get('files', {})
                        findings: List[SecurityFinding] = []
                        for file_path, file_data in files_data.items():
                            for i, finding in enumerate(file_data.get('findings', [])):
                                try:
                                    finding['file_path'] = file_path
                                    file_id = os.path.basename(file_path).replace('.', '_').replace('-', '_')
                                    finding['rule_id'] = f"{finding.get('rule_id', 'vulnerability')}_{file_id}_{i+1}"
                                    findings.append(SecurityFinding(**finding))
                                except Exception as e:
                                    logger.warning(f"Failed to create SecurityFinding for {file_path}: {e}")
                                    continue
                        batch_time = (datetime.now() - batch_start_time).total_seconds()
                        logger.info(f"âœ… SHARD BATCH {batch_num + 1} COMPLETE: {len(findings)} findings in {batch_time:.1f}s")
                        return findings
                    else:
                        logger.error(f"âŒ SHARD BATCH {batch_num + 1}: No JSON found in response")
                        return []
                except Exception as api_error:
                    if "429" in str(api_error) or "rate_limit" in str(api_error).lower():
                        if attempt < max_retries - 1:
                            import time as _t
                            delay = base_delay * (2 ** attempt)
                            logger.warning(f"âš ï¸ SHARD BATCH {batch_num + 1}: Rate limited, retrying in {delay:.1f}s (attempt {attempt + 1}/{max_retries})")
                            _t.sleep(delay)
                            continue
                    logger.error(f"âŒ SHARD BATCH {batch_num + 1}: API error: {api_error}")
                    return []
        except Exception as e:
            logger.error(f"âŒ SHARD BATCH {batch_num + 1} failed: {e}")
            return []
    
    def analyze_files_batch_sync(self, batch_files: List[tuple], batch_num: int, total_batches: int, scan_start_time: datetime, max_scan_time: int) -> List[SecurityFinding]:
        """ðŸš€ THREAD POOL VERSION: Analyze multiple files in ONE API call for true parallel processing"""
        try:
            if not batch_files:
                return []
            
            # Check if we're approaching timeout
            elapsed_time = (datetime.now() - scan_start_time).total_seconds()
            if elapsed_time > max_scan_time - 60:  # Stop 1 minute before timeout
                logger.warning(f"âš ï¸ THREAD BATCH {batch_num + 1}: Approaching scan timeout ({elapsed_time:.0f}s), stopping early")
                return []
            
            batch_start_time = datetime.now()
            logger.info(f"ðŸ“¦ THREAD BATCH {batch_num + 1}/{total_batches} (files: {len(batch_files)}) - STARTING")
            
            # Update progress for batch processing
            try:
                if self.progress_tracker:
                    self.progress_tracker.update_progress(f"Analyzing batch {batch_num + 1}/{total_batches}", batch_num + 1)
                    logger.info(f"ðŸ“Š PROGRESS: Thread batch {batch_num + 1}/{total_batches} - Progress updated successfully")
                else:
                    logger.warning(f"âš ï¸ PROGRESS: No progress tracker available for thread batch {batch_num + 1}")
            except Exception as e:
                logger.error(f"âŒ PROGRESS ERROR: Failed to update progress for thread batch {batch_num + 1}: {e}")
                # Don't let progress tracking break the scan, but log the error
            
            # Build comprehensive batch prompt with content chunking
            batch_content = []
            for file_path, relative_path, file_type in batch_files:
                try:
                    with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                        content = f.read()
                    
                    # PHASE 3: CONTENT CHUNKING for large files
                    if len(content) > 12000:  # Increased from 8000
                        # Smart chunking: Split by functions/classes for better analysis
                        chunks = self.chunk_file_content(content, relative_path, file_type)
                        if chunks:
                            # Use first chunk for batch analysis, others will be analyzed separately
                            content = chunks[0]
                            logger.info(f"ðŸ“„ PHASE 3 CHUNKING: {relative_path} split into {len(chunks)} chunks, using first chunk")
                        else:
                            # Fallback: simple truncation
                            content = content[:12000] + "\n... [truncated for batch analysis]"
                    elif len(content) > 8000:
                        content = content[:8000] + "\n... [truncated for batch analysis]"
                    
                    batch_content.append({
                        'file_path': relative_path,
                        'file_type': file_type,
                        'content': content
                    })
                except Exception as e:
                    logger.warning(f"âš ï¸ Failed to read {relative_path} for batch analysis: {e}")
                    continue
            
            if not batch_content:
                return []
            
            # Create ONE comprehensive prompt for ALL files
            prompt = f"""
            You are an expert security engineer. Analyze MULTIPLE files for security vulnerabilities in ONE response.
            
            FILES TO ANALYZE:
            {json.dumps(batch_content, indent=2)}
            
            For EACH file, identify security vulnerabilities focusing on:
            - Authentication & authorization bypasses
            - Input validation & injection attacks
            - Data exposure & privacy violations
            - Cryptography & secrets management
            - Session management issues
            - File upload security
            - API security vulnerabilities
            - Frontend security (XSS, CSRF)
            - Backend security (SQL injection, etc.)
            - Business logic flaws
            - Error handling & information disclosure
            
            Return findings in this EXACT JSON format:
            {{
                "files": {{
                    "file_path_1": {{
                        "findings": [
                            {{
                                "rule_id": "vulnerability_type_identifier",
                                "severity": "Critical|High|Medium|Low",
                                "message": "Brief vulnerability description",
                                "description": "Detailed explanation",
                                "file_path": "file_path_1",
                                "line_number": 123,
                                "end_line": 125,
                                "code_snippet": "vulnerable code here",
                                "cwe_ids": ["CWE-79", "CWE-89"],
                                "owasp_ids": ["A01:2021", "A03:2021"],
                                "impact": "High|Medium|Low",
                                "likelihood": "High|Medium|Low",
                                "confidence": "High|Medium|Low"
                            }}
                        ]
                    }},
                    "file_path_2": {{
                        "findings": [...]
                    }}
                }}
            }}
            
            Be thorough but practical. Focus on real-world risks that indie developers face.
            
            IMPORTANT: For rule_id, use a descriptive identifier like "xss_vulnerability", "sql_injection", "csrf_missing", etc. NOT generic numbers like "VULN-001".
            """
            
            # ðŸš€ MULTI-API KEY THREAD POOL PROCESSING: Each batch gets its own API key!
            api_key_index = batch_num % len(self.api_keys)  # Distribute batches across API keys
            selected_api_key = self.api_keys[api_key_index]
            
            logger.info(f"ðŸš€ THREAD BATCH {batch_num + 1}: Using API key {api_key_index + 1}/{len(self.api_keys)}")
            
            # ðŸš€ IMPLEMENT RATE LIMITING PROTECTION with exponential backoff
            max_retries = 3
            base_delay = 1.0  # Start with 1 second delay
            
            for attempt in range(max_retries):
                try:
                    # ONE API CALL for ALL files in batch
                    client = openai.OpenAI(api_key=selected_api_key)
                    response = client.chat.completions.create(
                        model="gpt-4o-mini",
                        messages=[
                            {"role": "system", "content": "You are an expert security engineer analyzing multiple files efficiently."},
                            {"role": "user", "content": prompt}
                        ],
                        max_tokens=8000,  # Increased for batch analysis
                        temperature=0.1
                    )
                    
                    # Track token usage
                    self.api_calls_made += 1
                    if hasattr(response, 'usage') and response.usage:
                        self.prompt_tokens += response.usage.prompt_tokens
                        self.completion_tokens += response.usage.completion_tokens
                        self.total_tokens_used += response.usage.total_tokens
                        logger.info(f"ðŸš€ THREAD BATCH {batch_num + 1}: Processed {len(batch_files)} files in 1 API call! Tokens: {response.usage.total_tokens}")
                    
                    # Parse the batch response
                    content = response.choices[0].message.content
                    try:
                        json_start = content.find('{')
                        json_end = content.rfind('}') + 1
                        
                        if json_start != -1 and json_end > json_start:
                            json_content = content[json_start:json_end]
                            result = json.loads(json_content)
                            
                            all_findings = []
                            files_data = result.get('files', {})
                            
                            for file_path, file_data in files_data.items():
                                findings = file_data.get('findings', [])
                                for i, finding in enumerate(findings):
                                    try:
                                        # Ensure file_path is correct
                                        finding['file_path'] = file_path
                                        
                                        # Ensure unique rule_id by adding file identifier and counter
                                        file_id = os.path.basename(file_path).replace('.', '_').replace('-', '_')
                                        unique_rule_id = f"{finding.get('rule_id', 'vulnerability')}_{file_id}_{i+1}"
                                        finding['rule_id'] = unique_rule_id
                                        
                                        security_finding = SecurityFinding(**finding)
                                        all_findings.append(security_finding)
                                    except Exception as e:
                                        logger.warning(f"Failed to create SecurityFinding for {file_path}: {e}")
                                        continue
                            
                            batch_time = (datetime.now() - batch_start_time).total_seconds()
                            logger.info(f"âœ… THREAD BATCH {batch_num + 1} COMPLETE: {len(all_findings)} findings in {batch_time:.1f}s")
                            
                            # ðŸš€ ADVANCED CACHING: Cache batch analysis result
                            batch_content_str = json.dumps(batch_content, sort_keys=True)
                            self.cache_result(batch_content_str, all_findings, "batch")
                            
                            return all_findings
                        else:
                            logger.error(f"âŒ THREAD BATCH {batch_num + 1}: No JSON found in response")
                            return []
                            
                    except json.JSONDecodeError as e:
                        logger.error(f"âŒ THREAD BATCH {batch_num + 1}: Failed to parse response: {e}")
                        return []
                    
                except Exception as api_error:
                    if "rate_limit" in str(api_error).lower() or "429" in str(api_error):
                        if attempt < max_retries - 1:
                            delay = base_delay * (2 ** attempt)  # Exponential backoff
                            logger.warning(f"âš ï¸ THREAD BATCH {batch_num + 1}: Rate limited, retrying in {delay:.1f}s (attempt {attempt + 1}/{max_retries})")
                            import time
                            time.sleep(delay)
                            continue
                        else:
                            logger.error(f"âŒ THREAD BATCH {batch_num + 1}: Rate limit exceeded after {max_retries} attempts")
                            return []
                    else:
                        logger.error(f"âŒ THREAD BATCH {batch_num + 1}: API error: {api_error}")
                        return []
            
            return []
            
        except Exception as e:
            logger.error(f"âŒ THREAD BATCH {batch_num + 1} failed: {e}")
            return []
    
    async def analyze_files_batch_async(self, batch_files: List[tuple], batch_num: int, total_batches: int, scan_start_time: datetime, max_scan_time: int) -> List[SecurityFinding]:
        """ðŸš€ ASYNC VERSION: Analyze multiple files in ONE API call for parallel processing"""
        try:
            if not batch_files:
                return []
            
            # Check if we're approaching timeout
            elapsed_time = (datetime.now() - scan_start_time).total_seconds()
            if elapsed_time > max_scan_time - 60:  # Stop 1 minute before timeout
                logger.warning(f"âš ï¸ BATCH {batch_num + 1}: Approaching scan timeout ({elapsed_time:.0f}s), stopping early")
                return []
            
            batch_start_time = datetime.now()
            logger.info(f"ðŸ“¦ PARALLEL BATCH {batch_num + 1}/{total_batches} (files: {len(batch_files)}) - STARTING")
            
            # Update progress for parallel batch processing
            try:
                if self.progress_tracker:
                    self.progress_tracker.update_progress(f"Processing batch {batch_num + 1}/{total_batches}", batch_num + 1)
                    logger.info(f"ðŸ“Š PROGRESS: Parallel batch {batch_num + 1}/{total_batches} - Progress updated successfully")
                else:
                    logger.warning(f"âš ï¸ PROGRESS: No progress tracker available for parallel batch {batch_num + 1}")
            except Exception as e:
                logger.error(f"âŒ PROGRESS ERROR: Failed to update progress for parallel batch {batch_num + 1}: {e}")
                # Don't let progress tracking break the scan, but log the error
            
            # Build comprehensive batch prompt with content chunking
            batch_content = []
            for file_path, relative_path, file_type in batch_files:
                try:
                    with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                        content = f.read()
                    
                    # PHASE 3: CONTENT CHUNKING for large files
                    if len(content) > 12000:  # Increased from 8000
                        # Smart chunking: Split by functions/classes for better analysis
                        chunks = self.chunk_file_content(content, relative_path, file_type)
                        if chunks:
                            # Use first chunk for batch analysis, others will be analyzed separately
                            content = chunks[0]
                            logger.info(f"ðŸ“„ PHASE 3 CHUNKING: {relative_path} split into {len(chunks)} chunks, using first chunk")
                        else:
                            # Fallback: simple truncation
                            content = content[:12000] + "\n... [truncated for batch analysis]"
                    elif len(content) > 8000:
                        content = content[:8000] + "\n... [truncated for batch analysis]"
                    
                    batch_content.append({
                        'file_path': relative_path,
                        'file_type': file_type,
                        'content': content
                    })
                except Exception as e:
                    logger.warning(f"âš ï¸ Failed to read {relative_path} for batch analysis: {e}")
                    continue
            
            if not batch_content:
                return []
            
            # Create ONE comprehensive prompt for ALL files
            prompt = f"""
            You are an expert security engineer. Analyze MULTIPLE files for security vulnerabilities in ONE response.
            
            FILES TO ANALYZE:
            {json.dumps(batch_content, indent=2)}
            
            For EACH file, identify security vulnerabilities focusing on:
            - Authentication & authorization bypasses
            - Input validation & injection attacks
            - Data exposure & privacy violations
            - Cryptography & secrets management
            - Session management issues
            - File upload security
            - API security vulnerabilities
            - Frontend security (XSS, CSRF)
            - Backend security (SQL injection, etc.)
            - Business logic flaws
            - Error handling & information disclosure
            
            Return findings in this EXACT JSON format:
            {{
                "files": {{
                    "file_path_1": {{
                        "findings": [
                            {{
                                "rule_id": "vulnerability_type_identifier",
                                "severity": "Critical|High|Medium|Low",
                                "message": "Brief vulnerability description",
                                "description": "Detailed explanation",
                                "file_path": "file_path_1",
                                "line_number": 123,
                                "end_line": 125,
                                "code_snippet": "vulnerable code here",
                                "cwe_ids": ["CWE-79", "CWE-89"],
                                "owasp_ids": ["A01:2021", "A03:2021"],
                                "impact": "High|Medium|Low",
                                "likelihood": "High|Medium|Low",
                                "confidence": "High|Medium|Low"
                            }}
                        ]
                    }},
                    "file_path_2": {{
                        "findings": [...]
                    }}
                }}
            }}
            
            Be thorough but practical. Focus on real-world risks that indie developers face.
            
            IMPORTANT: For rule_id, use a descriptive identifier like "xss_vulnerability", "sql_injection", "csrf_missing", etc. NOT generic numbers like "VULN-001".
            """
            
            # ðŸš€ MULTI-API KEY PARALLEL PROCESSING: Each batch gets its own API key!
            api_key_index = batch_num % len(self.api_keys)  # Distribute batches across API keys
            selected_api_key = self.api_keys[api_key_index]
            
            logger.info(f"ðŸš€ PARALLEL BATCH {batch_num + 1}: Using API key {api_key_index + 1}/{len(self.api_keys)}")
            
            # ONE API CALL for ALL files in batch
            client = openai.OpenAI(api_key=selected_api_key)
            response = client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "system", "content": "You are an expert security engineer analyzing multiple files efficiently."},
                    {"role": "user", "content": prompt}
                ],
                max_tokens=8000,  # Increased for batch analysis
                temperature=0.1
            )
            
            # Track token usage
            self.api_calls_made += 1
            if hasattr(response, 'usage') and response.usage:
                self.prompt_tokens += response.usage.prompt_tokens
                self.completion_tokens += response.usage.completion_tokens
                self.total_tokens_used += response.usage.total_tokens
                logger.info(f"ðŸš€ PARALLEL BATCH {batch_num + 1}: Processed {len(batch_files)} files in 1 API call! Tokens: {response.usage.total_tokens}")
            
            # Parse the batch response
            content = response.choices[0].message.content
            try:
                json_start = content.find('{')
                json_end = content.rfind('}') + 1
                
                if json_start != -1 and json_end > json_start:
                    json_content = content[json_start:json_end]
                    result = json.loads(json_content)
                    
                    all_findings = []
                    files_data = result.get('files', {})
                    
                    for file_path, file_data in files_data.items():
                        findings = file_data.get('findings', [])
                        for i, finding in enumerate(findings):
                            try:
                                # Ensure file_path is correct
                                finding['file_path'] = file_path
                                
                                # Ensure unique rule_id by adding file identifier and counter
                                file_id = os.path.basename(file_path).replace('.', '_').replace('-', '_')
                                unique_rule_id = f"{finding.get('rule_id', 'vulnerability')}_{file_id}_{i+1}"
                                finding['rule_id'] = unique_rule_id
                                
                                security_finding = SecurityFinding(**finding)
                                all_findings.append(security_finding)
                            except Exception as e:
                                logger.warning(f"Failed to create SecurityFinding for {file_path}: {e}")
                                continue
                    
                    batch_time = (datetime.now() - batch_start_time).total_seconds()
                    logger.info(f"âœ… PARALLEL BATCH {batch_num + 1} COMPLETE: {len(all_findings)} findings in {batch_time:.1f}s")
                    return all_findings
                else:
                    logger.error(f"âŒ PARALLEL BATCH {batch_num + 1}: No JSON found in response")
                    return []
                    
            except json.JSONDecodeError as e:
                logger.error(f"âŒ PARALLEL BATCH {batch_num + 1}: Failed to parse response: {e}")
                return []
            
        except Exception as e:
            logger.error(f"âŒ PARALLEL BATCH {batch_num + 1} failed: {e}")
            return []
    
    def analyze_files_batch(self, batch_files: List[tuple]) -> List[SecurityFinding]:
        """Analyze multiple files in ONE API call for massive optimization"""
        try:
            if not batch_files:
                return []
            
            logger.info(f"ðŸš€ BATCH ANALYSIS: Processing {len(batch_files)} files in ONE API call!")
            
            # Build comprehensive batch prompt with content chunking
            batch_content = []
            for file_path, relative_path, file_type in batch_files:
                try:
                    with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                        content = f.read()
                    
                    # PHASE 3: CONTENT CHUNKING for large files
                    if len(content) > 12000:  # Increased from 8000
                        # Smart chunking: Split by functions/classes for better analysis
                        chunks = self.chunk_file_content(content, relative_path, file_type)
                        if chunks:
                            # Use first chunk for batch analysis, others will be analyzed separately
                            content = chunks[0]
                            logger.info(f"ðŸ“„ PHASE 3 CHUNKING: {relative_path} split into {len(chunks)} chunks, using first chunk")
                        else:
                            # Fallback: simple truncation
                            content = content[:12000] + "\n... [truncated for batch analysis]"
                    elif len(content) > 8000:
                        content = content[:8000] + "\n... [truncated for batch analysis]"
                    
                    batch_content.append({
                        'file_path': relative_path,
                        'file_type': file_type,
                        'content': content
                    })
                except Exception as e:
                    logger.warning(f"âš ï¸ Failed to read {relative_path} for batch analysis: {e}")
                    continue
            
            if not batch_content:
                return []
            
            # Create ONE comprehensive prompt for ALL files
            prompt = f"""
            You are an expert security engineer. Analyze MULTIPLE files for security vulnerabilities in ONE response.
            
            FILES TO ANALYZE:
            {json.dumps(batch_content, indent=2)}
            
            For EACH file, identify security vulnerabilities focusing on:
            - Authentication & authorization bypasses
            - Input validation & injection attacks
            - Data exposure & privacy violations
            - Cryptography & secrets management
            - Session management issues
            - File upload security
            - API security vulnerabilities
            - Frontend security (XSS, CSRF)
            - Backend security (SQL injection, etc.)
            - Business logic flaws
            - Error handling & information disclosure
            
            Return findings in this EXACT JSON format:
            {{
                "files": {{
                    "file_path_1": {{
                        "findings": [
                            {{
                                "rule_id": "vulnerability_type_identifier",
                                "severity": "Critical|High|Medium|Low",
                                "message": "Brief vulnerability description",
                                "description": "Detailed explanation",
                                "file_path": "file_path_1",
                                "line_number": 123,
                                "end_line": 125,
                                "code_snippet": "vulnerable code here",
                                "cwe_ids": ["CWE-79", "CWE-89"],
                                "owasp_ids": ["A01:2021", "A03:2021"],
                                "impact": "High|Medium|Low",
                                "likelihood": "High|Medium|Low",
                                "confidence": "High|Medium|Low"
                            }}
                        ]
                    }},
                    "file_path_2": {{
                        "findings": [...]
                    }}
                }}
            }}
            
            Be thorough but practical. Focus on real-world risks that indie developers face.
            
            IMPORTANT: For rule_id, use a descriptive identifier like "xss_vulnerability", "sql_injection", "csrf_missing", etc. NOT generic numbers like "VULN-001".
            """
            
            # MULTI-API KEY PARALLEL PROCESSING: Use round-robin API key selection
            api_key_index = self.api_calls_made % len(self.api_keys)
            selected_api_key = self.api_keys[api_key_index]
            
            logger.info(f"ðŸš€ MULTI-API KEY: Using API key {api_key_index + 1}/{len(self.api_keys)} for batch analysis")
            
            # ONE API CALL for ALL files in batch
            client = openai.OpenAI(api_key=selected_api_key)
            response = client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[
                    {"role": "system", "content": "You are an expert security engineer analyzing multiple files efficiently."},
                    {"role": "user", "content": prompt}
                ],
                max_tokens=8000,  # Increased for batch analysis
                temperature=0.1
            )
            
            # Track token usage
            self.api_calls_made += 1
            if hasattr(response, 'usage') and response.usage:
                self.prompt_tokens += response.usage.prompt_tokens
                self.completion_tokens += response.usage.completion_tokens
                self.total_tokens_used += response.usage.total_tokens
                logger.info(f"ðŸš€ BATCH ANALYSIS: Processed {len(batch_files)} files in 1 API call! Tokens: {response.usage.total_tokens}")
            
            # Parse the batch response
            content = response.choices[0].message.content
            try:
                json_start = content.find('{')
                json_end = content.rfind('}') + 1
                
                if json_start != -1 and json_end > json_start:
                    json_content = content[json_start:json_end]
                    result = json.loads(json_content)
                    
                    all_findings = []
                    files_data = result.get('files', {})
                    
                    for file_path, file_data in files_data.items():
                        findings = file_data.get('findings', [])
                        for i, finding in enumerate(findings):
                            try:
                                # Ensure file_path is correct
                                finding['file_path'] = file_path
                                
                                # Ensure unique rule_id by adding file identifier and counter
                                file_id = os.path.basename(file_path).replace('.', '_').replace('-', '_')
                                unique_rule_id = f"{finding.get('rule_id', 'vulnerability')}_{file_id}_{i+1}"
                                finding['rule_id'] = unique_rule_id
                                
                                security_finding = SecurityFinding(**finding)
                                all_findings.append(security_finding)
                            except Exception as e:
                                logger.warning(f"Failed to create SecurityFinding for {file_path}: {e}")
                                continue
                    
                    logger.info(f"âœ… BATCH ANALYSIS: Successfully parsed {len(all_findings)} findings from {len(batch_files)} files")
                    return all_findings
                else:
                    logger.error("âŒ No JSON found in batch analysis response")
                    return []
                    
            except json.JSONDecodeError as e:
                logger.error(f"âŒ Failed to parse batch analysis response: {e}")
                logger.error("Response content omitted for security")
                return []
            
        except Exception as e:
            logger.error(f"âŒ Batch analysis failed: {e}")
            return []
    
    def chunk_file_content(self, content: str, file_path: str, file_type: str) -> List[str]:
        """PHASE 3: Smart content chunking for large files"""
        try:
            if len(content) <= 12000:
                return [content]
            
            chunks = []
            
            # Language-specific chunking strategies
            if file_type in ['.js', '.ts', '.jsx', '.tsx']:
                # JavaScript/TypeScript: Split by functions, classes, and major sections
                lines = content.split('\n')
                current_chunk = []
                chunk_size = 0
                
                for line in lines:
                    # Check for major section boundaries
                    if any(keyword in line for keyword in [
                        'function ', 'class ', 'export ', 'import ', 'const ', 'let ', 'var ',
                        'interface ', 'type ', 'enum ', 'namespace '
                    ]):
                        # If current chunk is getting large, start a new one
                        if chunk_size > 8000 and current_chunk:
                            chunks.append('\n'.join(current_chunk))
                            current_chunk = []
                            chunk_size = 0
                    
                    current_chunk.append(line)
                    chunk_size += len(line) + 1
                    
                    # Force chunk break if getting too large
                    if chunk_size > 12000:
                        chunks.append('\n'.join(current_chunk))
                        current_chunk = []
                        chunk_size = 0
                
                # Add remaining content
                if current_chunk:
                    chunks.append('\n'.join(current_chunk))
            
            elif file_type in ['.py']:
                # Python: Split by functions, classes, and major sections
                lines = content.split('\n')
                current_chunk = []
                chunk_size = 0
                
                for line in lines:
                    # Check for major section boundaries
                    if any(keyword in line for keyword in [
                        'def ', 'class ', 'import ', 'from ', 'if __name__', 'async def '
                    ]):
                        # If current chunk is getting large, start a new one
                        if chunk_size > 8000 and current_chunk:
                            chunks.append('\n'.join(current_chunk))
                            current_chunk = []
                            chunk_size = 0
                    
                    current_chunk.append(line)
                    chunk_size += len(line) + 1
                    
                    # Force chunk break if getting too large
                    if chunk_size > 12000:
                        chunks.append('\n'.join(current_chunk))
                        current_chunk = []
                        chunk_size = 0
                
                # Add remaining content
                if current_chunk:
                    chunks.append('\n'.join(current_chunk))
            
            else:
                # Generic chunking: Split by lines
                lines = content.split('\n')
                chunk_size = 12000
                for i in range(0, len(lines), chunk_size):
                    chunk_lines = lines[i:i + chunk_size]
                    chunks.append('\n'.join(chunk_lines))
            
            logger.info(f"ðŸ“„ PHASE 3 CHUNKING: {file_path} split into {len(chunks)} chunks")
            return chunks
            
        except Exception as e:
            logger.error(f"âŒ Content chunking failed for {file_path}: {e}")
            return [content]  # Return original content as single chunk
    
    def get_cached_result(self, file_path: str, file_content_hash: str) -> Optional[List[SecurityFinding]]:
        """PHASE 4: Get cached analysis result if available"""
        cache_key = f"{file_path}_{file_content_hash}"
        if cache_key in self.result_cache:
            logger.info(f"ðŸ“‹ PHASE 4 CACHE HIT: Using cached result for {file_path}")
            return self.result_cache[cache_key]
        return None
    
    def cache_result(self, file_path: str, file_content_hash: str, findings: List[SecurityFinding]):
        """PHASE 4: Cache analysis result for future use"""
        cache_key = f"{file_path}_{file_content_hash}"
        self.result_cache[cache_key] = findings
        logger.info(f"ðŸ“‹ PHASE 4 CACHE STORE: Cached result for {file_path}")
    
    def calculate_file_risk_score(self, file_path: str, file_content: str) -> float:
        """PHASE 4: Calculate risk score for file based on content patterns"""
        try:
            risk_score = 0.0
            content_lower = file_content.lower()
            
            # High-risk patterns
            high_risk_patterns = [
                'password', 'secret', 'api_key', 'token', 'auth', 'login', 'register',
                'sql', 'query', 'database', 'db.', 'exec', 'eval', 'innerhtml',
                'localstorage', 'sessionstorage', 'cookie', 'jwt', 'oauth'
            ]
            
            for pattern in high_risk_patterns:
                if pattern in content_lower:
                    risk_score += 0.1
            
            # Medium-risk patterns
            medium_risk_patterns = [
                'input', 'form', 'upload', 'file', 'user', 'admin', 'root',
                'config', 'env', 'process.env', 'window.', 'document.'
            ]
            
            for pattern in medium_risk_patterns:
                if pattern in content_lower:
                    risk_score += 0.05
            
            # Normalize risk score to 0-1 range
            risk_score = min(1.0, risk_score)
            
            # Store risk score for future reference
            self.file_risk_scores[file_path] = risk_score
            
            return risk_score
            
        except Exception as e:
            logger.error(f"âŒ Risk score calculation failed for {file_path}: {e}")
            return 0.5  # Default medium risk
    
    def should_analyze_file_deep(self, file_path: str, file_content: str) -> bool:
        """PHASE 4: Determine if file needs deep analysis based on risk score"""
        risk_score = self.calculate_file_risk_score(file_path, file_content)
        
        # High-risk files (risk_score > 0.7) always get deep analysis
        if risk_score > 0.7:
            logger.info(f"ðŸŽ¯ PHASE 4 ML: {file_path} marked as HIGH RISK (score: {risk_score:.2f}) - Deep analysis required")
            return True
        
        # Medium-risk files (risk_score > 0.4) get standard analysis
        elif risk_score > 0.4:
            logger.info(f"ðŸŽ¯ PHASE 4 ML: {file_path} marked as MEDIUM RISK (score: {risk_score:.2f}) - Standard analysis")
            return True
        
        # Low-risk files (risk_score <= 0.4) get quick analysis or skip
        else:
            logger.info(f"ðŸŽ¯ PHASE 4 ML: {file_path} marked as LOW RISK (score: {risk_score:.2f}) - Quick analysis only")
            return False

    def get_file_analysis_rules(self, file_path: str) -> Dict[str, Any]:
        """Universal analysis rules for ALL tech stacks to reduce false positives"""
        file_path_lower = file_path.lower()
        
        # Database & Backend Configuration (ALL platforms)
        if any(term in file_path_lower for term in [
            'firebase', 'supabase', 'mongodb', 'postgres', 'mysql', 'sqlite',
            'prisma', 'sequelize', 'typeorm', 'drizzle', 'knex'
        ]):
            return {
                'ignore_patterns': [
                    'NEXT_PUBLIC_', 'NUXT_PUBLIC_', 'VITE_PUBLIC_', 'SVELTE_PUBLIC_',
                    'process.env.public', 'import.meta.env.public', 'window.env.public',
                    'database config', 'db config', 'connection string', 'connection_string',
                    'public database', 'public connection', 'public endpoint'
                ],
                'focus_on': [
                    'authentication logic',
                    'database security rules',
                    'user permission handling',
                    'sql injection prevention',
                    'data validation'
                ],
                'skip_checks': [
                    'environment_variable_exposure',
                    'config_file_exposure',
                    'public_key_exposure',
                    'database_config_exposure'
                ]
            }
        
        # OAuth & Authentication (ALL platforms)
        elif any(term in file_path_lower for term in [
            'oauth', 'auth', 'github', 'google', 'facebook', 'discord', 'twitter',
            'login', 'register', 'signin', 'signup', 'authentication'
        ]):
            return {
                'ignore_patterns': [
                    'client id', 'client_id', 'redirect uri', 'redirect_uri',
                    'oauth config', 'auth config', 'public oauth', 'public auth',
                    'github client', 'google client', 'facebook client', 'discord client'
                ],
                'focus_on': [
                    'state validation',
                    'token handling',
                    'session management',
                    'authentication bypasses',
                    'csrf protection',
                    'password security'
                ],
                'skip_checks': [
                    'oauth_config_exposure',
                    'client_secret_exposure',
                    'redirect_uri_exposure'
                ]
            }
        
        # API & Backend Routes (ALL platforms)
        elif any(term in file_path_lower for term in [
            'api/', 'routes/', 'controllers/', 'handlers/', 'endpoints/',
            'middleware/', 'services/', 'utils/', 'helpers/'
        ]):
            return {
                'ignore_patterns': [],
                'focus_on': [
                    'input validation',
                    'authentication checks',
                    'authorization logic',
                    'rate limiting',
                    'error handling',
                    'sql injection prevention',
                    'xss prevention'
                ],
                'skip_checks': []
            }
        
        # Frontend Components & Pages (ALL frameworks)
        elif any(term in file_path_lower for term in [
            'component', 'page', 'ui', 'view', 'screen', 'layout',
            'react', 'vue', 'svelte', 'angular', 'ember', 'next', 'nuxt'
        ]):
            return {
                'ignore_patterns': [
                    'public props', 'component props', 'ui configuration',
                    'theme config', 'style config', 'css config', 'design system'
                ],
                'focus_on': [
                    'XSS prevention',
                    'user input handling',
                    'dangerouslySetInnerHTML usage',
                    'client-side validation',
                    'csrf protection',
                    'secure data handling'
                ],
                'skip_checks': [
                    'component_prop_exposure',
                    'ui_config_exposure',
                    'theme_exposure'
                ]
            }
        
        # Configuration & Build Files (ALL platforms)
        elif any(term in file_path_lower for term in [
            'config', 'env', 'setup', 'webpack', 'vite', 'rollup', 'esbuild',
            'babel', 'typescript', 'tailwind', 'postcss', 'eslint', 'prettier'
        ]):
            return {
                'ignore_patterns': [
                    'NEXT_PUBLIC_', 'NUXT_PUBLIC_', 'VITE_PUBLIC_', 'SVELTE_PUBLIC_',
                    'process.env.public', 'import.meta.env.public', 'window.env.public',
                    'public config', 'build config', 'framework config'
                ],
                'focus_on': [
                    'security settings',
                    'authentication config',
                    'CORS configuration',
                    'security headers',
                    'build security'
                ],
                'skip_checks': [
                    'config_file_exposure',
                    'environment_exposure',
                    'build_config_exposure'
                ]
            }
        
        # Package & Dependency Files (ALL platforms)
        elif any(term in file_path_lower for term in [
            'package.json', 'composer.json', 'requirements.txt', 'gemfile',
            'cargo.toml', 'go.mod', 'pom.xml', 'build.gradle', 'yarn.lock'
        ]):
            return {
                'ignore_patterns': [
                    'dependency list', 'package list', 'module list',
                    'version info', 'license info', 'author info'
                ],
                'focus_on': [
                    'vulnerable dependencies',
                    'outdated packages',
                    'security advisories',
                    'license compliance'
                ],
                'skip_checks': [
                    'package_exposure',
                    'dependency_exposure',
                    'version_exposure'
                ]
            }
        
        # Default rules for other files
        return {
            'ignore_patterns': [],
            'focus_on': ['all'],
            'skip_checks': []
        }

    # ðŸš€ ADVANCED CACHING METHODS
    
    def generate_cache_key(self, content: str, cache_type: str = "file") -> str:
        """Generate unique cache key based on content and type"""
        # Create hash of content
        content_hash = hashlib.sha256(content.encode('utf-8')).hexdigest()
        
        # Add cache type and timestamp for better organization
        timestamp = int(time.time() / (self.cache_ttl_hours * 3600))  # Hour-based timestamp
        return f"{cache_type}:{content_hash}:{timestamp}"
    
    def normalize_code_content(self, content: str) -> str:
        """Normalize code content for better pattern matching"""
        # Remove comments, whitespace, and normalize
        lines = content.split('\n')
        normalized_lines = []
        
        for line in lines:
            # Remove comments
            if '//' in line:
                line = line.split('//')[0]
            if '#' in line:
                line = line.split('#')[0]
            if '/*' in line:
                continue  # Skip multi-line comments
            
            # Remove extra whitespace
            line = line.strip()
            if line:
                normalized_lines.append(line)
        
        return '\n'.join(normalized_lines)
    
    def calculate_content_similarity(self, content1: str, content2: str) -> float:
        """Calculate similarity between two code contents"""
        if not content1 or not content2:
            return 0.0
        
        # Normalize both contents
        norm1 = self.normalize_code_content(content1)
        norm2 = self.normalize_code_content(content2)
        
        if norm1 == norm2:
            return 1.0
        
        # Simple similarity calculation (can be enhanced with more sophisticated algorithms)
        words1 = set(norm1.split())
        words2 = set(norm2.split())
        
        if not words1 or not words2:
            return 0.0
        
        intersection = words1.intersection(words2)
        union = words1.union(words2)
        
        return len(intersection) / len(union) if union else 0.0
    
    def get_cached_result(self, content: str, cache_type: str = "file") -> Optional[Any]:
        """Get cached result if available and not expired"""
        try:
            # Clean up cache periodically
            self._cleanup_cache_if_needed()
            
            # Generate cache key
            cache_key = self.generate_cache_key(content, cache_type)
            
            # Check file cache first
            if cache_type == "file" and cache_key in self.file_cache:
                result = self.file_cache[cache_key]
                if self._is_cache_valid(result):
                    self.cache_stats['hits'] += 1
                    self.cache_stats['total_requests'] += 1
                    logger.info(f"ðŸŽ¯ CACHE HIT: {cache_type} analysis found in cache")
                    return result['data']
            
            # Check pattern cache for similar content
            if cache_type == "file":
                similar_result = self._find_similar_pattern(content)
                if similar_result:
                    self.cache_stats['hits'] += 1
                    self.cache_stats['total_requests'] += 1
                    logger.info(f"ðŸŽ¯ PATTERN CACHE HIT: Similar content found in cache")
                    return similar_result
            
            # Check batch cache
            if cache_type == "batch" and cache_key in self.batch_cache:
                result = self.batch_cache[cache_key]
                if self._is_cache_valid(result):
                    self.cache_stats['hits'] += 1
                    self.cache_stats['total_requests'] += 1
                    logger.info(f"ðŸŽ¯ CACHE HIT: Batch analysis found in cache")
                    return result['data']
            
            # Cache miss
            self.cache_stats['misses'] += 1
            self.cache_stats['total_requests'] += 1
            logger.info(f"ðŸ”„ CACHE MISS: {cache_type} analysis not found in cache")
            return None
            
        except Exception as e:
            logger.error(f"âŒ Cache retrieval error: {e}")
            return None
    
    def cache_result(self, content: str, result: Any, cache_type: str = "file") -> None:
        """Cache analysis result with TTL and LRU management"""
        try:
            # Generate cache key
            cache_key = self.generate_cache_key(content, cache_type)
            
            # Create cache entry with metadata
            cache_entry = {
                'data': result,
                'timestamp': time.time(),
                'size': len(str(result)),
                'type': cache_type
            }
            
            # Add to appropriate cache
            if cache_type == "file":
                self._add_to_lru_cache(self.file_cache, cache_key, cache_entry)
            elif cache_type == "batch":
                self._add_to_lru_cache(self.batch_cache, cache_key, cache_entry)
            elif cache_type == "pattern":
                self._add_to_lru_cache(self.pattern_cache, cache_key, cache_entry)
            
            # Update cache statistics
            self.cache_stats['cache_size'] = len(self.file_cache) + len(self.batch_cache) + len(self.pattern_cache)
            self.cache_stats['memory_usage_mb'] = self._calculate_cache_memory_usage()
            
            logger.info(f"ðŸ’¾ CACHED: {cache_type} analysis result cached (key: {cache_key[:16]}...)")
            
        except Exception as e:
            logger.error(f"âŒ Cache storage error: {e}")
    
    def _add_to_lru_cache(self, cache: OrderedDict, key: str, value: Any) -> None:
        """Add item to LRU cache with size management"""
        # Remove oldest items if cache is full
        while len(cache) >= self.max_cache_size:
            cache.popitem(last=False)  # Remove oldest item
        
        # Add new item
        cache[key] = value
        
        # Move to end (most recently used)
        cache.move_to_end(key)
    
    def _is_cache_valid(self, cache_entry: Dict) -> bool:
        """Check if cache entry is still valid (not expired)"""
        if not cache_entry or 'timestamp' not in cache_entry:
            return False
        
        age_hours = (time.time() - cache_entry['timestamp']) / 3600
        return age_hours < self.cache_ttl_hours
    
    def _find_similar_pattern(self, content: str) -> Optional[Any]:
        """Find similar pattern in pattern cache"""
        normalized_content = self.normalize_code_content(content)
        
        for cache_key, cache_entry in self.pattern_cache.items():
            if not self._is_cache_valid(cache_entry):
                continue
            
            cached_content = cache_entry.get('original_content', '')
            if not cached_content:
                continue
            
            similarity = self.calculate_content_similarity(normalized_content, cached_content)
            if similarity >= self.pattern_similarity_threshold:
                logger.info(f"ðŸŽ¯ PATTERN MATCH: Found {similarity:.2f} similarity match")
                return cache_entry['data']
        
        return None
    
    def _cleanup_cache_if_needed(self) -> None:
        """Clean up expired cache entries"""
        current_time = time.time()
        if current_time - self.last_cache_cleanup < self.cache_cleanup_interval:
            return
        
        logger.info("ðŸ§¹ CACHE CLEANUP: Starting cache cleanup...")
        
        # Clean up expired entries
        for cache_name, cache in [('file', self.file_cache), ('batch', self.batch_cache), ('pattern', self.pattern_cache)]:
            expired_keys = [key for key, entry in cache.items() if not self._is_cache_valid(entry)]
            for key in expired_keys:
                del cache[key]
            if expired_keys:
                logger.info(f"ðŸ§¹ CACHE CLEANUP: Removed {len(expired_keys)} expired entries from {cache_name} cache")
        
        # Update statistics
        self.cache_stats['cache_size'] = len(self.file_cache) + len(self.batch_cache) + len(self.pattern_cache)
        self.cache_stats['memory_usage_mb'] = self._calculate_cache_memory_usage()
        
        self.last_cache_cleanup = current_time
        logger.info(f"ðŸ§¹ CACHE CLEANUP: Complete. Cache size: {self.cache_stats['cache_size']}, Memory: {self.cache_stats['memory_usage_mb']:.2f}MB")
    
    def _calculate_cache_memory_usage(self) -> float:
        """Calculate approximate memory usage of cache in MB"""
        total_size = 0
        for cache in [self.file_cache, self.batch_cache, self.pattern_cache]:
            for entry in cache.values():
                total_size += len(str(entry))
        
        return total_size / (1024 * 1024)  # Convert to MB
    
    def get_cache_statistics(self) -> Dict[str, Any]:
        """Get comprehensive cache statistics"""
        hit_rate = (self.cache_stats['hits'] / max(self.cache_stats['total_requests'], 1)) * 100
        
        return {
            'cache_hits': self.cache_stats['hits'],
            'cache_misses': self.cache_stats['misses'],
            'total_requests': self.cache_stats['total_requests'],
            'hit_rate_percent': round(hit_rate, 2),
            'cache_size': self.cache_stats['cache_size'],
            'memory_usage_mb': round(self.cache_stats['memory_usage_mb'], 2),
            'file_cache_size': len(self.file_cache),
            'batch_cache_size': len(self.batch_cache),
            'pattern_cache_size': len(self.pattern_cache),
            'max_cache_size': self.max_cache_size,
            'cache_ttl_hours': self.cache_ttl_hours
        }

# Create Flask app
app = Flask(__name__)

# Enable CORS for all routes
CORS(app, origins=['*'], methods=['GET', 'POST', 'OPTIONS'])

# Progress tracking completely removed

# Progress tracking completely removed

# Add CORS headers
@app.after_request
def add_cors_headers(response):
    origin = request.headers.get('Origin')
    allowed_origins = [
        'http://localhost:9002',
        'http://localhost:3000',
        'https://vibecatcher.dev',
        'http://vibecatcher.dev'
    ]
    
    # Set CORS headers for all endpoints
    if origin in allowed_origins:
        response.headers['Access-Control-Allow-Origin'] = origin
    else:
        response.headers['Access-Control-Allow-Origin'] = 'http://localhost:9002'
    
    response.headers['Access-Control-Allow-Methods'] = 'GET, POST, OPTIONS'
    response.headers['Access-Control-Allow-Headers'] = 'Content-Type, Authorization'
    response.headers['Access-Control-Max-Age'] = '86400'  # 24 hours
    
    # Add debug logging for CORS
    logger.info(f"ðŸ”’ CORS: Origin={origin}, Allowed={origin in allowed_origins}")
    
    return response

@app.route('/', methods=['OPTIONS'])
def handle_options():
    response = jsonify({'status': 'ok'})
    response.headers['Access-Control-Allow-Origin'] = '*'
    response.headers['Access-Control-Allow-Methods'] = 'GET, POST, OPTIONS'
    response.headers['Access-Control-Allow-Headers'] = 'Content-Type'
    return response

# Progress tracking completely removed

@app.route('/', methods=['GET'])
def health_check():
    """Health check endpoint"""
    logger.info("ðŸ¥ Health check requested")
    
    # Check critical dependencies
    checks = {
        'openai_api_key': bool(os.environ.get('OPENAI_API_KEY')),
        'port': int(os.environ.get('PORT', 8080)),
        'python_version': f"{os.sys.version_info.major}.{os.sys.version_info.minor}.{os.sys.version_info.micro}",
        'working_directory': os.getcwd(),
        'files_in_working_dir': len(os.listdir('.'))
    }
    
    return jsonify({
        'status': 'healthy',
        'service': 'chatgpt-security-scanner',
        'timestamp': datetime.now().isoformat(),
        'version': '1.0.0',
        'cors_enabled': True,
        'timeout_configured': '900s',
        'batch_processing': True,
        'health_checks': checks
    })

@app.route('/progress', methods=['GET'])
def get_progress():
    """Get current scan progress for real-time updates"""
    try:
        # Use global scan state for cross-thread access
        global current_scan_state, current_scan_lock
        
        with current_scan_lock:
            scan_state = current_scan_state.copy()
        
        # DEBUG: Log what we're getting from global state
        logger.info(f"ðŸ“Š PROGRESS ENDPOINT: global_scan_state = {scan_state}")
        logger.info(f"ðŸ“Š PROGRESS ENDPOINT: is_running = {scan_state.get('is_running', 'NOT_FOUND')}")
        logger.info(f"ðŸ“Š PROGRESS ENDPOINT: step = {scan_state.get('step', 'NOT_FOUND')}")
        logger.info(f"ðŸ“Š PROGRESS ENDPOINT: percentage = {scan_state.get('percentage', 'NOT_FOUND')}")
        
        if not scan_state.get('is_running', False):
            logger.warning(f"ðŸ“Š PROGRESS ENDPOINT: Returning no_scan_running - is_running: {scan_state.get('is_running', 'NOT_FOUND')}")
            logger.warning(f"ðŸ“Š PROGRESS ENDPOINT: Current step: {scan_state.get('step', 'NOT_FOUND')}")
            logger.warning(f"ðŸ“Š PROGRESS ENDPOINT: Current percentage: {scan_state.get('percentage', 'NOT_FOUND')}")
            return jsonify({
                'status': 'no_scan_running',
                'message': 'No security scan is currently running'
            })
        
        # Format time remaining for frontend
        if scan_state.get('remaining_seconds') is not None:
            remaining_minutes = int(scan_state['remaining_seconds'] // 60)
            remaining_seconds = int(scan_state['remaining_seconds'] % 60)
            if remaining_minutes > 0:
                time_remaining = f"{remaining_minutes}m {remaining_seconds}s"
            else:
                time_remaining = f"{remaining_seconds}s"
        else:
            time_remaining = "Calculating..."
        
        # Format elapsed time
        elapsed_minutes = int(scan_state.get('elapsed_seconds', 0) // 60)
        elapsed_seconds = int(scan_state.get('elapsed_seconds', 0) % 60)
        if elapsed_minutes > 0:
            elapsed_time = f"{elapsed_minutes}m {elapsed_seconds}s"
        else:
            elapsed_time = f"{elapsed_seconds}s"
        
        return jsonify({
            'status': 'scan_running',
            'step': scan_state.get('step', 'Unknown'),
            'percentage': scan_state.get('percentage', 0),
            'elapsed_time': elapsed_time,
            'time_remaining': time_remaining,
            'completed_tasks': scan_state.get('completed_tasks', 0),
            'total_tasks': scan_state.get('total_tasks', 0),
            'timestamp': datetime.now().isoformat()
        })
        
    except Exception as e:
        logger.error(f"âŒ Progress endpoint error: {e}")
        return jsonify({
            'status': 'error',
            'message': 'Failed to get progress data'
        }), 500

@app.route('/progress/reset', methods=['POST'])
def reset_progress():
    """Reset progress tracker for new scan"""
    try:
        progress_tracker.cleanup()
        return jsonify({
            'status': 'success',
            'message': 'Progress tracker reset successfully'
        })
    except Exception as e:
        logger.error(f"âŒ Progress reset error: {e}")
        return jsonify({
            'status': 'error',
            'message': 'Failed to reset progress tracker'
        }), 500

@app.route('/cleanup-stuck-audit', methods=['POST'])
def cleanup_stuck_audit():
    """Clean up stuck audit by resetting progress and clearing state"""
    try:
        data = request.get_json()
        audit_id = data.get('audit_id')
        
        if not audit_id:
            return jsonify({'error': 'audit_id is required'}), 400
        
        # Reset progress tracker
        progress_tracker.cleanup()
        
        # Clear any temporary files
        import os
        temp_file = f"/tmp/security_scanner_progress_{audit_id}.json"
        if os.path.exists(temp_file):
            os.remove(temp_file)
        
        logger.info(f"ðŸ§¹ Cleaned up stuck audit: {audit_id}")
        return jsonify({'status': 'ok', 'message': f'Stuck audit {audit_id} cleaned up'})
    except Exception as e:
        logger.error(f"âŒ Failed to cleanup stuck audit: {e}")
        return jsonify({'error': str(e)}), 500

@app.route('/debug/global-state', methods=['GET'])
def debug_global_state():
    """Debug endpoint to inspect global scan state"""
    try:
        global current_scan_state, current_scan_lock
        
        with current_scan_lock:
            scan_state = current_scan_state.copy()
        
        return jsonify({
            'status': 'success',
            'global_scan_state': scan_state,
            'timestamp': datetime.now().isoformat(),
            'thread_info': {
                'current_thread': str(threading.current_thread()),
                'active_threads': len(threading.enumerate())
            }
        })
    except Exception as e:
        logger.error(f"âŒ Debug global state error: {e}")
        return jsonify({'error': str(e)}), 500

@app.route('/cache-stats', methods=['GET'])
def get_cache_statistics():
    """Get comprehensive cache statistics and performance metrics"""
    try:
        # Get cache statistics from the scanner instance
        if hasattr(app, 'scanner') and app.scanner:
            cache_stats = app.scanner.get_cache_statistics()
        else:
            # Create a temporary scanner instance to get stats
            temp_scanner = ChatGPTSecurityScanner()
            cache_stats = temp_scanner.get_cache_statistics()
        
        # Add additional performance metrics
        performance_metrics = {
            'cache_efficiency': {
                'hit_rate_percent': cache_stats.get('hit_rate_percent', 0),
                'cost_savings_estimate': f"${cache_stats.get('cache_hits', 0) * 0.02:.2f}",
                'api_calls_saved': cache_stats.get('cache_hits', 0),
                'estimated_time_saved_minutes': cache_stats.get('cache_hits', 0) * 0.5  # 30 seconds per cached file
            },
            'cache_performance': {
                'cache_size': cache_stats.get('cache_size', 0),
                'memory_usage_mb': cache_stats.get('memory_usage_mb', 0),
                'max_cache_size': cache_stats.get('max_cache_size', 10000),
                'cache_ttl_hours': cache_stats.get('cache_ttl_hours', 24)
            },
            'cache_distribution': {
                'file_cache_size': cache_stats.get('file_cache_size', 0),
                'batch_cache_size': cache_stats.get('batch_cache_size', 0),
                'pattern_cache_size': cache_stats.get('pattern_cache_size', 0)
            }
        }
        
        response_data = {
            'status': 'success',
            'timestamp': datetime.now().isoformat(),
            'cache_statistics': cache_stats,
            'performance_metrics': performance_metrics,
            'cache_benefits': {
                'description': 'Advanced multi-level caching system with pattern matching',
                'features': [
                    'File-level caching for individual analysis results',
                    'Batch caching for multi-file analysis',
                    'Pattern caching for similar code structures',
                    'LRU cache management with TTL expiration',
                    'Intelligent similarity matching',
                    'Memory usage optimization'
                ],
                'cost_savings': f"Estimated ${cache_stats.get('cache_hits', 0) * 0.02:.2f} saved in API costs",
                'time_savings': f"Estimated {cache_stats.get('cache_hits', 0) * 0.5:.1f} minutes saved in processing time"
            }
        }
        
        logger.info(f"ðŸ“Š CACHE STATS: Retrieved cache statistics - {cache_stats.get('hit_rate_percent', 0)}% hit rate")
        return jsonify(response_data)
        
    except Exception as e:
        logger.error(f"âŒ Error retrieving cache statistics: {e}")
        return jsonify({
            'status': 'error',
            'message': f'Failed to retrieve cache statistics: {str(e)}',
            'timestamp': datetime.now().isoformat()
        }), 500

@app.route('/internal/shard-scan', methods=['POST'])
def shard_scan():
    """Internal endpoint to process assigned batches from a peer orchestrator.
    Requires Authorization: Bearer WORKER_AUTH_TOKEN when configured.
    """
    try:
        token_header = request.headers.get('Authorization', '')
        token = token_header.replace('Bearer ', '') if token_header.startswith('Bearer ') else token_header
        required = os.environ.get('WORKER_AUTH_TOKEN', '')
        if required and token != required:
            return jsonify({'error': 'Unauthorized'}), 401

        payload = request.get_json(silent=True) or {}
        batches_content = payload.get('batches_content', [])
        if not isinstance(batches_content, list):
            return jsonify({'error': 'Invalid payload'}), 400

        scanner = ChatGPTSecurityScanner()

        # Analyze each content batch directly (no filesystem dependency)
        all_results: List[SecurityFinding] = []
        for idx, content_batch in enumerate(batches_content):
            findings = scanner.analyze_files_batch_from_payload(content_batch, idx, len(batches_content), datetime.now(), 900)
            all_results.extend(findings)

        serialized = []
        for finding in all_results:
            if isinstance(finding, SecurityFinding):
                serialized.append(asdict(finding))
            elif isinstance(finding, dict):
                serialized.append(finding)

        return jsonify({'status': 'ok', 'findings': serialized})
    except Exception as e:
        logger.error(f"âŒ shard_scan failed: {e}")
        return jsonify({'error': 'shard_scan_failed'}), 500

@app.route('/', methods=['POST'])
def security_scan():
    """Main endpoint for security scans"""
    try:
        data = request.get_json()
        if not data:
            return jsonify({'error': 'No data provided'}), 400
        
        repo_url = data.get('repository_url')
        github_token = data.get('github_token')
        audit_id = data.get('audit_id')
        progress_webhook_url = data.get('progress_webhook_url')
        # Progress tracking removed
        
        # Input validation
        if not repo_url:
            return jsonify({'error': 'repository_url is required'}), 400
        
        # Validate repository URL format
        if not isinstance(repo_url, str):
            return jsonify({'error': 'repository_url must be a string'}), 400
        
        if not repo_url.startswith('https://github.com/'):
            return jsonify({'error': 'repository_url must be a valid GitHub HTTPS URL'}), 400
        
        # Validate GitHub token format if provided
        if github_token:
            if not isinstance(github_token, str):
                return jsonify({'error': 'github_token must be a string'}), 400
            
            if not github_token.startswith(('ghp_', 'gho_', 'ghu_')):
                return jsonify({'error': 'Invalid GitHub token format'}), 400
        
        logger.info(f"ðŸš€ Starting security scan for: {repo_url}")
        
        # Progress tracking removed
        
        # Run the scan with NUCLEAR TIMEOUT PROTECTION
        try:
            scanner = ChatGPTSecurityScanner()
            
            # CRITICAL: Pass the progress tracker to the scanner so it can actually update progress
            scanner.set_progress_tracker(progress_tracker)
            
            # Initialize progress tracking - estimate based on repository size
            # We'll use a reasonable estimate since we don't know exact batch count yet
            estimated_batches = 30  # Conservative estimate for most repos
            
            # Start progress tracking for new scan (cleanup happens automatically)
            # Also set global webhook context for pushing progress
            global GLOBAL_AUDIT_ID, GLOBAL_PROGRESS_WEBHOOK_URL, GLOBAL_LAST_PROGRESS_WEBHOOK_SENT_TS, GLOBAL_LAST_PROGRESS_STEP, GLOBAL_LAST_PROGRESS_PERCENT
            GLOBAL_AUDIT_ID = audit_id
            GLOBAL_PROGRESS_WEBHOOK_URL = progress_webhook_url
            GLOBAL_LAST_PROGRESS_WEBHOOK_SENT_TS = 0.0
            GLOBAL_LAST_PROGRESS_STEP = None
            GLOBAL_LAST_PROGRESS_PERCENT = None
            progress_tracker.start_progress(estimated_batches, "Initializing security scan...")
            
            # DEBUG: Log the global state after starting progress
            logger.info(f"ðŸ” DEBUG: Global scan state after start_progress: {current_scan_state}")
            
            # Set a hard timeout for the entire scan
            scan_timeout = 600  # 10 minutes max (Cloud Run timeout is 15 minutes)
            
            logger.info(f"ðŸš€ Starting scan with {scan_timeout}s timeout protection")
            
            # Update progress for scan start
            progress_tracker.update_progress("Starting repository analysis...", 0)
            logger.info(f"ðŸ” DEBUG: Global scan state after update 1: {current_scan_state}")
            
            # Update progress for scan execution
            progress_tracker.update_progress("Executing security analysis...", 5)
            logger.info(f"ðŸ” DEBUG: Global scan state after update 2: {current_scan_state}")
            
            # Run with timeout protection using asyncio.run()
            logger.info(f"ðŸš€ EXECUTING SCAN: scanner.scan_repository()")
            
            # Update progress to show scan is actively running
            progress_tracker.update_progress("Scanning repository files...", 25)
            
            result = asyncio.run(asyncio.wait_for(
                scanner.scan_repository(repo_url, github_token),
                timeout=scan_timeout
            ))
            logger.info(f"ðŸš€ SCAN EXECUTION COMPLETED: {result}")
            
            # Update progress for scan completion
            progress_tracker.update_progress("Finalizing scan results...", 95)
            
            # Check if scan failed
            if 'error' in result:
                logger.error(f"Scan failed: {result['error']}")
                return jsonify(result), 500
            
            logger.info(f"âœ… Scan completed successfully in {result.get('scan_duration', 0):.1f}s")
            
            # Complete progress tracking
            progress_tracker.complete_progress("Scan completed successfully!")
            # Ensure a final webhook push at 100%
            try:
                maybe_send_progress_webhook("Scan completed successfully!", 100.0)
            except Exception:
                pass
            
            # Send completion webhook if URL provided
            if progress_webhook_url:
                try:
                    import requests
                    webhook_payload = {
                        'audit_id': audit_id,
                        'status': 'completed',
                        'progress': {
                            'step': 'Scan completed successfully!',
                            'progress': 100,
                            'timestamp': datetime.now().isoformat()
                        },
                        'scan_results': result
                    }
                    requests.post(progress_webhook_url, json=webhook_payload, timeout=10)
                    logger.info(f"ðŸ“¡ Completion webhook sent to: {progress_webhook_url}")
                except Exception as webhook_error:
                    logger.warning(f"âš ï¸ Failed to send completion webhook: {webhook_error}")
            
            return jsonify(result)
            
        except asyncio.TimeoutError:
            logger.error(f"âŒ Scan timed out after {scan_timeout}s")
            progress_tracker.complete_progress("Scan timed out")
            try:
                maybe_send_progress_webhook("Scan timed out", 100.0)
            except Exception:
                pass
            
            # Send timeout webhook if URL provided
            if progress_webhook_url:
                try:
                    import requests
                    webhook_payload = {
                        'audit_id': audit_id,
                        'status': 'failed',
                        'progress': {
                            'step': 'Scan timed out',
                            'progress': 100,
                            'timestamp': datetime.now().isoformat()
                        },
                        'error': f'Scan timed out after {scan_timeout}s - repository too large or complex',
                        'error_type': 'TimeoutError'
                    }
                    requests.post(progress_webhook_url, json=webhook_payload, timeout=10)
                    logger.info(f"ðŸ“¡ Timeout webhook sent to: {progress_webhook_url}")
                except Exception as webhook_error:
                    logger.warning(f"âš ï¸ Failed to send timeout webhook: {webhook_error}")
            
            return jsonify({
                'error': f'Scan timed out after {scan_timeout}s - repository too large or complex',
                'error_type': 'TimeoutError',
                'scan_duration': scan_timeout,
                'timestamp': datetime.now().isoformat()
            }), 408
        except Exception as scan_error:
            logger.error(f"âŒ Scan execution error: {scan_error}")
            progress_tracker.complete_progress("Scan failed with error")
            try:
                maybe_send_progress_webhook("Scan failed with error", 100.0)
            except Exception:
                pass
            
            # Send error webhook if URL provided
            if progress_webhook_url:
                try:
                    import requests
                    webhook_payload = {
                        'audit_id': audit_id,
                        'status': 'failed',
                        'progress': {
                            'step': 'Scan failed with error',
                            'progress': 100,
                            'timestamp': datetime.now().isoformat()
                        },
                        'error': str(scan_error),
                        'error_type': type(scan_error).__name__
                    }
                    requests.post(progress_webhook_url, json=webhook_payload, timeout=10)
                    logger.info(f"ðŸ“¡ Error webhook sent to: {progress_webhook_url}")
                except Exception as webhook_error:
                    logger.warning(f"âš ï¸ Failed to send error webhook: {webhook_error}")
            
            return jsonify({
                'error': str(scan_error),
                'error_type': type(scan_error).__name__,
                'timestamp': datetime.now().isoformat()
            }), 500
        
    except Exception as e:
        logger.error(f"HTTP handler error: {e}")
        return jsonify({'error': str(e), 'error_type': type(e).__name__}), 500

if __name__ == "__main__":
    try:
        # Cleanup progress tracker on shutdown
        import atexit
        atexit.register(progress_tracker.cleanup)
        
        # Read port from environment variable (Cloud Run requirement)
        port = int(os.environ.get('PORT', 8080))
        logger.info(f"ðŸš€ NUCLEAR OPTIMIZED ChatGPT Security Scanner starting on port {port}")
        logger.info(f"ðŸ” Environment: PORT={port}")
        logger.info(f"ðŸ”’ CORS enabled for all endpoints")
        logger.info(f"â±ï¸  Scan timeout protection: 900s")
        logger.info(f"ðŸš€ PHASE 1: Smart file filtering + Batch analysis (3-5x faster)")
        logger.info(f"ðŸš€ PHASE 2: Multi-API key parallel processing (ready for multiple keys)")
        logger.info(f"ðŸš€ PHASE 3: Content chunking + Pattern pre-filtering")
        logger.info(f"ðŸš€ PHASE 4: Caching + ML-based optimization")
        logger.info(f"ðŸš€ PHASE 5: TRUE PARALLEL PROCESSING with ThreadPoolExecutor + Rate Limiting Protection (5-10x faster!)")
        logger.info(f"âš ï¸  IMPORTANT: Set Cloud Run timeout to 900s (15 minutes) to avoid 504 errors")
        logger.info(f"âš ï¸  IMPORTANT: Ensure OPENAI_API_KEY is set")
        logger.info(f"ðŸš€ EXPECTED PERFORMANCE: 20 minutes â†’ 1-2 minutes (15x faster with parallel processing!)")
        
        # Test OpenAI API key availability
        api_key = os.environ.get('OPENAI_API_KEY')
        if not api_key:
            logger.error("âŒ OPENAI_API_KEY environment variable is not set!")
            logger.error("âŒ Container will not start without this variable")
            exit(1)
        else:
            logger.info(f"âœ… OPENAI_API_KEY is configured (length: {len(api_key)})")
        
        # Resource validation
        import multiprocessing
        cpu_count = multiprocessing.cpu_count()
        logger.info(f"ðŸš€ System resources: {cpu_count} CPU cores available")
        logger.info(f"ðŸš€ Memory: 4GB allocated, optimizing for maximum performance")
        
        if cpu_count < 2:
            logger.warning(f"âš ï¸ Low CPU count ({cpu_count}), performance may be limited")
        else:
            logger.info(f"âœ… CPU count ({cpu_count}) sufficient for nuclear optimization")
        
        # Start the Flask app
        logger.info(f"ðŸš€ Flask app starting on 0.0.0.0:{port}")
        logger.info(f"ðŸš€ ALL NUCLEAR PHASES ENABLED: 4GB RAM + 4 CPU cores + Multi-API keys")
        logger.info(f"ðŸš€ FINAL PERFORMANCE TARGET: 20 minutes â†’ 2-3 minutes (10x faster!)")
        app.run(host='0.0.0.0', port=port, debug=False)
        
    except Exception as e:
        logger.error(f"âŒ Failed to start container: {e}")
        logger.error(f"âŒ Error type: {type(e).__name__}")
        import traceback
        logger.error(f"âŒ Traceback: {traceback.format_exc()}")
        exit(1)
